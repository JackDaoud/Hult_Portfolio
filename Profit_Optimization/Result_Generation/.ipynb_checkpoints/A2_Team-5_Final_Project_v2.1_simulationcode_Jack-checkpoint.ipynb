{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-26T00:01:18.103553Z",
     "start_time": "2021-03-26T00:01:18.096395Z"
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<br><br><br><br><br>\n",
    "<u><b><font size = 6>A2: Team Project OJ </f></b></u><br><br>\n",
    "<b><font size = 5> Data Optimization - DAT-5304 </f></b>\n",
    "<br><br>\n",
    "<b>Authors</b>          : Carolina Novello Moreira, Jack Daoud & Max Lembke <br>\n",
    "<b>Date Created</b> : 03/24/2021<br>\n",
    "<br><br><br><br><br>\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T01:22:17.968267Z",
     "start_time": "2021-04-01T01:22:16.545554Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'OJ_Data.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-afe647ff3691>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Importing file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'OJ_Data.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m                 )\n\u001b[1;32m    295\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         raise ValueError(\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine)\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstringify_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/excel/_xlrd.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0merr_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Install xlrd >= 1.0.0 for Excel support\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mimport_optional_dependency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"xlrd\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/excel/_xlrd.py\u001b[0m in \u001b[0;36mload_workbook\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/xlrd/__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[0;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m             \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpeek\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb\"PK\\x03\\x04\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# a ZIP file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'OJ_Data.xlsx'"
     ]
    }
   ],
   "source": [
    "# Import packages \n",
    "import pandas as pd #pandas \n",
    "import numpy  as np #numpy \n",
    "from numpy import arange # for ranges with floats\n",
    "import statsmodels.formula.api as smf # predictive modeling with nice outputs\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas import DataFrame\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Set options \n",
    "pd.set_option(\"display.max_rows\", 999)\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "\n",
    "# Importing file \n",
    "df = pd.read_excel('OJ_Data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T01:22:17.977015Z",
     "start_time": "2021-04-01T01:22:16.546Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Helper functions \n",
    "\n",
    "# Make binary function \n",
    "def make_binary(df):\n",
    "    \n",
    "    for col in df.columns:\n",
    "        \n",
    "        if 'feat' in col \\\n",
    "        or 'disp' in col:\n",
    "            \n",
    "            for index, value in df.iterrows():\n",
    "                \n",
    "                if df.loc[index, col] >= 0.5:\n",
    "                    df.loc[index, col] = 1\n",
    "                else:\n",
    "                    df.loc[index, col] = 0\n",
    "        \n",
    "            df[col] = df[col].astype(int)\n",
    "\n",
    "\n",
    "# Shuffle dataframe function\n",
    "def shuffle(df, n = 1, axis = 0):     \n",
    "    df = df.copy()\n",
    "    for _ in range(n):\n",
    "        df.apply(np.random.shuffle, axis = axis)\n",
    "        return df\n",
    "\n",
    "# Source:\n",
    "# https://stackoverflow.com/questions/15772009/shuffling-permutating-a-dataframe-in-pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T01:22:17.979190Z",
     "start_time": "2021-04-01T01:22:16.549Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data cleaning \n",
    "\n",
    "# Clean binary variables\n",
    "make_binary(df)\n",
    "\n",
    "\n",
    "# Log transformations \n",
    "\n",
    "# Price\n",
    "df['log_price1'] = np.log(df['price1'])\n",
    "df['log_price2'] = np.log(df['price2'])\n",
    "df['log_price3'] = np.log(df['price3'])\n",
    "df['log_price4'] = np.log(df['price4'])\n",
    "df['log_price5'] = np.log(df['price5'])\n",
    "\n",
    "# Sales\n",
    "df['log_sales1'] = np.log(df['sales1'])\n",
    "df['log_sales2'] = np.log(df['sales2'])\n",
    "df['log_sales3'] = np.log(df['sales3'])\n",
    "df['log_sales4'] = np.log(df['sales4'])\n",
    "df['log_sales5'] = np.log(df['sales5'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product 1: Tropicana Premium 64 oz\n",
    "\n",
    "### Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T01:22:17.979979Z",
     "start_time": "2021-04-01T01:22:16.551Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # step 1: build a model\n",
    "# lm_best = smf.ols(formula =  \"\"\"log_sales1 ~ log_price1 +\n",
    "#                                         log_price2 +\n",
    "#                                         log_price3 +\n",
    "#                                         log_price4 +\n",
    "#                                         log_price5 +\n",
    "#                                         disp1 +\n",
    "#                                         feat1\"\"\",\n",
    "#                                         data = df)\n",
    "\n",
    "\n",
    "# # step 2: fit the model based on the data\n",
    "# results_1 = lm_best.fit()\n",
    "\n",
    "# # step 3: analyze the summary output\n",
    "# print(results_1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T01:22:17.980865Z",
     "start_time": "2021-04-01T01:22:16.553Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Re-running the the regression without variables with p-values above 0.05\n",
    "\n",
    "# step 1: build a model\n",
    "lm_best = smf.ols(formula =  \"\"\"log_sales1 ~ log_price1 +\n",
    "                                        log_price3 +\n",
    "                                        disp1 +\n",
    "                                        feat1\"\"\",\n",
    "                                        data = df)\n",
    "\n",
    "\n",
    "# step 2: fit the model based on the data\n",
    "results_1_opt = lm_best.fit()\n",
    "\n",
    "# step 3: analyze the summary output\n",
    "print(results_1_opt.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gross Margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T01:22:17.981635Z",
     "start_time": "2021-04-01T01:22:16.556Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# step 1: build a model\n",
    "lm_best = smf.ols(formula =  \"\"\"grmar1 ~ log_price1\"\"\",\n",
    "                                        data = df)\n",
    "\n",
    "\n",
    "# step 2: fit the model based on the data\n",
    "results_grmar_1 = lm_best.fit()\n",
    "\n",
    "# step 3: analyze the summary output\n",
    "print(results_grmar_1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product 2: Tropicana Premium 96 oz\n",
    "\n",
    "### Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T01:22:17.982373Z",
     "start_time": "2021-04-01T01:22:16.558Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # step 1: build a model\n",
    "# lm_best = smf.ols(formula =  \"\"\"log_sales2 ~ log_price1 +\n",
    "#                                         log_price2 +\n",
    "#                                         log_price3 +\n",
    "#                                         log_price4 +\n",
    "#                                         log_price5 +\n",
    "#                                         disp2 +\n",
    "#                                         feat2\"\"\",\n",
    "#                                         data = df)\n",
    "\n",
    "\n",
    "# # step 2: fit the model based on the data\n",
    "# results_2 = lm_best.fit()\n",
    "\n",
    "# # step 3: analyze the summary output\n",
    "# print(results_2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T01:22:17.983231Z",
     "start_time": "2021-04-01T01:22:16.560Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Re-running the the regression without variables with p-values above 0.05\n",
    "\n",
    "# step 1: build a model\n",
    "lm_best = smf.ols(formula =  \"\"\"log_sales2 ~ log_price1 +\n",
    "                                        log_price2 +\n",
    "                                        disp2 +\n",
    "                                        feat2\"\"\",\n",
    "                                        data = df)\n",
    "\n",
    "\n",
    "# step 2: fit the model based on the data\n",
    "results_2_opt = lm_best.fit()\n",
    "\n",
    "# step 3: analyze the summary output\n",
    "print(results_2_opt.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gross Margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T01:22:17.984014Z",
     "start_time": "2021-04-01T01:22:16.562Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# step 1: build a model\n",
    "lm_best = smf.ols(formula =  \"\"\"grmar2 ~ log_price2\"\"\",\n",
    "                                        data = df)\n",
    "\n",
    "\n",
    "# step 2: fit the model based on the data\n",
    "results_grmar_2 = lm_best.fit()\n",
    "\n",
    "# step 3: analyze the summary output\n",
    "print(results_grmar_2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product 3: Topicana 64 oz\n",
    "\n",
    "### Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T01:22:17.984781Z",
     "start_time": "2021-04-01T01:22:16.564Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # step 1: build a model\n",
    "# lm_best = smf.ols(formula =  \"\"\"log_sales3 ~ log_price1 +\n",
    "#                                         log_price2 +\n",
    "#                                         log_price3 +\n",
    "#                                         log_price4 +\n",
    "#                                         log_price5 +\n",
    "#                                         disp3 +\n",
    "#                                         feat3\"\"\",\n",
    "#                                         data = df)\n",
    "\n",
    "\n",
    "# # step 2: fit the model based on the data\n",
    "# results_3 = lm_best.fit()\n",
    "\n",
    "# # step 3: analyze the summary output\n",
    "# print(results_3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T01:22:17.985592Z",
     "start_time": "2021-04-01T01:22:16.566Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Re-running the the regression without variables with p-values above 0.05\n",
    "\n",
    "# step 1: build a model\n",
    "lm_best = smf.ols(formula =  \"\"\"log_sales3 ~ log_price1 +\n",
    "                                        log_price3 +\n",
    "                                        log_price4 +\n",
    "                                        disp3 +\n",
    "                                        feat3\"\"\",\n",
    "                                        data = df)\n",
    "\n",
    "\n",
    "# step 2: fit the model based on the data\n",
    "results_3_opt = lm_best.fit()\n",
    "\n",
    "# step 3: analyze the summary output\n",
    "print(results_3_opt.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gross Margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T01:22:17.986377Z",
     "start_time": "2021-04-01T01:22:16.569Z"
    }
   },
   "outputs": [],
   "source": [
    "# step 1: build a model\n",
    "lm_best = smf.ols(formula =  \"\"\"grmar3 ~ log_price3\"\"\",\n",
    "                                        data = df)\n",
    "\n",
    "\n",
    "# step 2: fit the model based on the data\n",
    "results_grmar_3 = lm_best.fit()\n",
    "\n",
    "# step 3: analyze the summary output\n",
    "print(results_grmar_3.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product 4: Minute Maid 64 oz\n",
    "\n",
    "### Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T01:22:17.987152Z",
     "start_time": "2021-04-01T01:22:16.571Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # step 1: build a model\n",
    "# lm_best = smf.ols(formula =  \"\"\"log_sales4 ~ log_price1 +\n",
    "#                                         log_price2 +\n",
    "#                                         log_price3 +\n",
    "#                                         log_price4 +\n",
    "#                                         log_price5 +\n",
    "#                                         disp4 +\n",
    "#                                         feat4\"\"\",\n",
    "#                                         data = df)\n",
    "\n",
    "\n",
    "# # step 2: fit the model based on the data\n",
    "# results_4 = lm_best.fit()\n",
    "\n",
    "# # step 3: analyze the summary output\n",
    "# print(results_4.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T01:22:17.987969Z",
     "start_time": "2021-04-01T01:22:16.573Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Re-running the the regression without variables with p-values above 0.05\n",
    "\n",
    "# step 1: build a model\n",
    "lm_best = smf.ols(formula =  \"\"\"log_sales4 ~ log_price1 +\n",
    "                                        log_price3 +\n",
    "                                        log_price4 +\n",
    "                                        log_price5 +\n",
    "                                        disp4 +\n",
    "                                        feat4\"\"\",\n",
    "                                        data = df)\n",
    "\n",
    "\n",
    "# step 2: fit the model based on the data\n",
    "results_4_opt = lm_best.fit()\n",
    "\n",
    "# step 3: analyze the summary output\n",
    "print(results_4_opt.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gross Margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T01:22:17.988736Z",
     "start_time": "2021-04-01T01:22:16.575Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# step 1: build a model\n",
    "lm_best = smf.ols(formula =  \"\"\"grmar4 ~ log_price4\"\"\",\n",
    "                                        data = df)\n",
    "\n",
    "\n",
    "# step 2: fit the model based on the data\n",
    "results_grmar_4 = lm_best.fit()\n",
    "\n",
    "# step 3: analyze the summary output\n",
    "print(results_grmar_4.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product 5: Dominick's 64 oz\n",
    "\n",
    "### Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T01:22:17.989440Z",
     "start_time": "2021-04-01T01:22:16.577Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # step 1: build a model\n",
    "# lm_best = smf.ols(formula =  \"\"\"log_sales5 ~ log_price1 +\n",
    "#                                         log_price2 +\n",
    "#                                         log_price3 +\n",
    "#                                         log_price4 +\n",
    "#                                         log_price5 +\n",
    "#                                         disp5 +\n",
    "#                                         feat5\"\"\",\n",
    "#                                         data = df)\n",
    "\n",
    "\n",
    "# # step 2: fit the model based on the data\n",
    "# results_5 = lm_best.fit()\n",
    "\n",
    "# # step 3: analyze the summary output\n",
    "# print(results_5.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T01:22:17.990325Z",
     "start_time": "2021-04-01T01:22:16.578Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Re-running the the regression without variables with p-values above 0.05\n",
    "\n",
    "# step 1: build a model\n",
    "lm_best_opt = smf.ols(formula =  \"\"\"log_sales5 ~ log_price2 +\n",
    "                                        log_price3 +\n",
    "                                        log_price4 +\n",
    "                                        log_price5 +\n",
    "                                        disp5 +\n",
    "                                        feat5\"\"\",\n",
    "                                        data = df)\n",
    "\n",
    "\n",
    "# step 2: fit the model based on the data\n",
    "results_5_opt = lm_best_opt.fit()\n",
    "\n",
    "# step 3: analyze the summary output\n",
    "print(results_5_opt.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gross Margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T01:22:17.991041Z",
     "start_time": "2021-04-01T01:22:16.580Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# step 1: build a model\n",
    "lm_best = smf.ols(formula =  \"\"\"grmar5 ~ log_price5\"\"\",\n",
    "                                        data = df)\n",
    "\n",
    "\n",
    "# step 2: fit the model based on the data\n",
    "results_grmar_5 = lm_best.fit()\n",
    "\n",
    "# step 3: analyze the summary output\n",
    "print(results_grmar_5.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "# Part 2: Monte Carlo\n",
    "\n",
    "## Constant Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T01:22:17.991952Z",
     "start_time": "2021-04-01T01:22:16.582Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Setup constant variables\n",
    "\n",
    "# (Re-) Setting Seed, due to np limitations\n",
    "np.random.seed(42)  \n",
    "\n",
    "# Devisor for sigma \n",
    "\n",
    "d_sigma = 2 \n",
    "\n",
    "# Ounces per SKU\n",
    "oz_1 = 64\n",
    "oz_2 = 96\n",
    "oz_3 = 64\n",
    "oz_4 = 64\n",
    "oz_5 = 64\n",
    "\n",
    "############################\n",
    "# Historical Data Overview #\n",
    "############################\n",
    "\n",
    "# Average price per SKU\n",
    "price1_avg = round((df['price1'].mean() * oz_1),2)\n",
    "price2_avg = round((df['price2'].mean() * oz_2),2)\n",
    "price3_avg = round((df['price3'].mean() * oz_2),2)\n",
    "price4_avg = round((df['price4'].mean() * oz_4),2)\n",
    "price5_avg = round((df['price5'].mean() * oz_5),2)\n",
    "\n",
    "# Units sold per SKU\n",
    "units_sold_1 = round(df['sales1'].mean(),2)\n",
    "units_sold_2 = round(df['sales2'].mean(),2)\n",
    "units_sold_3 = round(df['sales3'].mean(),2)\n",
    "units_sold_4 = round(df['sales4'].mean(),2)\n",
    "units_sold_5 = round(df['sales5'].mean(),2)\n",
    "\n",
    "# Average gross margin per SKU\n",
    "grmar1_avg = round(df['grmar1'].mean()*100,2)\n",
    "grmar2_avg = round(df['grmar2'].mean()*100,2)\n",
    "grmar3_avg = round(df['grmar3'].mean()*100,2)\n",
    "grmar4_avg = round(df['grmar4'].mean()*100,2)\n",
    "grmar5_avg = round(df['grmar5'].mean()*100,2)\n",
    "\n",
    "# Revenue per SKU \n",
    "revenue_1 = df['sales1'] * oz_1 * df['price1']\n",
    "avg_revenue_1 = round(revenue_1.mean(),2)\n",
    "\n",
    "revenue_2 = df['sales2'] * oz_2 * df['price2']\n",
    "avg_revenue_2 = round(revenue_2.mean(),2)\n",
    "\n",
    "revenue_3 = df['sales3'] * oz_3 * df['price3']\n",
    "avg_revenue_3 = round(revenue_3.mean(),2)\n",
    "\n",
    "revenue_4 = df['sales4'] * oz_4 * df['price4']\n",
    "avg_revenue_4 = round(revenue_4.mean(),2)\n",
    "\n",
    "revenue_5 = df['sales5'] * oz_5 * df['price5']\n",
    "avg_revenue_5 = round(revenue_5.mean(),2)\n",
    "\n",
    "\n",
    "# Profits per SKU\n",
    "profits_1 = revenue_1 * df['grmar1']\n",
    "avg_profits_1 = round(profits_1.mean(),2)\n",
    "\n",
    "profits_2 = revenue_2 * df['grmar2']\n",
    "avg_profits_2 = round(profits_2.mean(),2)\n",
    "\n",
    "profits_3 = revenue_3 * df['grmar3']\n",
    "avg_profits_3 = round(profits_3.mean(),2)\n",
    "\n",
    "profits_4 = revenue_4 * df['grmar4']\n",
    "avg_profits_4 = round(profits_4.mean(),2)\n",
    "\n",
    "profits_5 = revenue_5 * df['grmar5']\n",
    "avg_profits_5 = round(profits_5.mean(),2)\n",
    "\n",
    "total_profits = profits_1 + profits_2 + profits_3 + profits_4 + profits_5\n",
    "avg_total_profits = round(total_profits.mean(),2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##################\n",
    "#  Gross Margin  #\n",
    "##############################################################################\n",
    "# Set up random draw parameters for coefficients - SKU1 (GRMAR)\n",
    "\n",
    "# intercept \n",
    "intercept_mu_GR1    = results_grmar_1.params[0]  # coefficient from regression\n",
    "intercept_sigma_GR1 = results_grmar_1.bse[0]     # standard error from regression\n",
    "\n",
    "# gross margin\n",
    "B1_mu_GR1    = results_grmar_1.params[1]\n",
    "B1_sigma_GR1 = results_grmar_1.bse[1]\n",
    "\n",
    "##############################################################################\n",
    "# Set up random draw parameters for coefficients - SKU2 (GRMAR)\n",
    "\n",
    "# intercept \n",
    "intercept_mu_GR2    = results_grmar_2.params[0]  # coefficient from regression\n",
    "intercept_sigma_GR2 = results_grmar_2.bse[0]    # standard error from regression\n",
    "\n",
    "# gross margin\n",
    "B1_mu_GR2    = results_grmar_2.params[1]\n",
    "B1_sigma_GR2 = results_grmar_2.bse[1]\n",
    "\n",
    "##############################################################################\n",
    "# Set up random draw parameters for coefficients - SKU3 (GRMAR)\n",
    "\n",
    "# intercept \n",
    "intercept_mu_GR3    = results_grmar_3.params[0]  # coefficient from regression\n",
    "intercept_sigma_GR3 = results_grmar_3.bse[0]     # standard error from regression\n",
    "\n",
    "# gross margin\n",
    "B1_mu_GR3    = results_grmar_3.params[1]\n",
    "B1_sigma_GR3 = results_grmar_3.bse[1]\n",
    "\n",
    "##############################################################################\n",
    "# Set up random draw parameters for coefficients - SKU4 (GRMAR)\n",
    "\n",
    "# intercept \n",
    "intercept_mu_GR4    = results_grmar_4.params[0]  # coefficient from regression\n",
    "intercept_sigma_GR4 = results_grmar_4.bse[0]     # standard error from regression\n",
    "\n",
    "# gross margin\n",
    "B1_mu_GR4    = results_grmar_4.params[1]\n",
    "B1_sigma_GR4 = results_grmar_4.bse[1]\n",
    "\n",
    "##############################################################################\n",
    "# Set up random draw parameters for coefficients - SKU5 (GRMAR)\n",
    "\n",
    "# intercept \n",
    "intercept_mu_GR5    = results_grmar_5.params[0]  # coefficient from regression\n",
    "intercept_sigma_GR5 = results_grmar_5.bse[0]     # standard error from regression\n",
    "\n",
    "# gross margin\n",
    "B1_mu_GR5    = results_grmar_5.params[1]\n",
    "B1_sigma_GR5 = results_grmar_5.bse[1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###########\n",
    "#  Sales  #\n",
    "##############################################################################\n",
    "# Set up random draw parameters for coefficients - SKU1 (Sales)\n",
    "\n",
    "# intercept \n",
    "intercept_mu_1    = results_1_opt.params[0]          # coefficient from regression\n",
    "intercept_sigma_1 = results_1_opt.bse[0]/d_sigma     # standard error from regression\n",
    "\n",
    "# price SKU1\n",
    "B1_mu_P1_1    = results_1_opt.params[1]              # coefficient from regression\n",
    "B1_sigma_P1_1 = results_1_opt.bse[1]/d_sigma         # standard error from regression\n",
    "\n",
    "# price SKU3\n",
    "B2_mu_P3_1    = results_1_opt.params[2]              # coefficient from regression\n",
    "B2_sigma_P3_1 = results_1_opt.bse[2]/d_sigma         # standard error from regression\n",
    "\n",
    "# disp1 SKU1\n",
    "B3_mu_D1_1 = results_1_opt.params[3]                 # coefficient from regression\n",
    "\n",
    "# feat1 SKU1\n",
    "B4_mu_F1_1 = results_1_opt.params[4]                 # coefficient from regression\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# Set up random draw parameters for coefficients - SKU2 (Sales)\n",
    "\n",
    "# intercept \n",
    "intercept_mu_2    = results_2_opt.params[0]         # coefficient from regression\n",
    "intercept_sigma_2 = results_2_opt.bse[0]/d_sigma    # standard error from regression\n",
    "\n",
    "# price SKU1\n",
    "B1_mu_P1_2    = results_2_opt.params[1]             # coefficient from regression\n",
    "B1_sigma_P1_2 = results_2_opt.bse[1]/d_sigma        # standard error from regression\n",
    "\n",
    "# price SKU2\n",
    "B2_mu_P2_2    = results_2_opt.params[2]             # coefficient from regression\n",
    "B2_sigma_P2_2 = results_2_opt.bse[2]/d_sigma        # standard error from regression\n",
    "\n",
    "# disp2 SKU2\n",
    "B3_mu_D2_2 = results_2_opt.params[3]                # coefficient from regression\n",
    "\n",
    "# feat2 SKU2\n",
    "B4_mu_F2_2 = results_2_opt.params[4]                # coefficient from regression\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# Set up random draw parameters for coefficients - SKU3 (Sales)\n",
    "\n",
    "# intercept \n",
    "intercept_mu_3    = results_3_opt.params[0]          # coefficient from regression\n",
    "intercept_sigma_3 = results_3_opt.bse[0]/d_sigma     # standard error from regression\n",
    "\n",
    "# price SKU1\n",
    "B1_mu_P1_3    = results_3_opt.params[1]              # coefficient from regression\n",
    "B1_sigma_P1_3 = results_3_opt.bse[1]/d_sigma         # standard error from regression\n",
    "\n",
    "# price SKU3 \n",
    "B2_mu_P3_3    = results_3_opt.params[2]              # coefficient from regression\n",
    "B2_sigma_P3_3 = results_3_opt.bse[2]/d_sigma         # standard error from regression\n",
    "\n",
    "# feat2 SKU4\n",
    "B3_mu_P4_3    = results_3_opt.params[3]              # coefficient from regression\n",
    "B3_sigma_P4_3 = results_3_opt.bse[3]/d_sigma         # standard error from regression\n",
    "\n",
    "# disp3 SKU3\n",
    "B4_mu_D3_3 = results_3_opt.params[4]                 # coefficient from regression\n",
    "\n",
    "# feat3 SKU3\n",
    "B5_mu_F3_3 = results_3_opt.params[5]                 # coefficient from regression\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# Set up random draw parameters for coefficients - SKU4 (Sales)\n",
    "\n",
    "# intercept \n",
    "intercept_mu_4    = results_4_opt.params[0]          # coefficient from regression\n",
    "intercept_sigma_4 = results_4_opt.bse[0]/d_sigma     # standard error from regression\n",
    "\n",
    "# price SKU1\n",
    "B1_mu_P1_4    = results_4_opt.params[1]              # coefficient from regression\n",
    "B1_sigma_P1_4 = results_4_opt.bse[1]/d_sigma         # standard error from regression\n",
    "\n",
    "# price SKU3\n",
    "B2_mu_P3_4    = results_4_opt.params[2]              # coefficient from regression\n",
    "B2_sigma_P3_4 = results_4_opt.bse[2]/d_sigma         # standard error from regression\n",
    "\n",
    "# price  SKU4\n",
    "B3_mu_P4_4    = results_4_opt.params[3]              # coefficient from regression\n",
    "B3_sigma_P4_4 = results_4_opt.bse[3]/d_sigma         # standard error from regression\n",
    "\n",
    "# price SKU5\n",
    "B4_mu_P5_4    = results_4_opt.params[4]              # coefficient from regression\n",
    "B4_sigma_P5_4 = results_4_opt.bse[4]/d_sigma         # standard error from regression\n",
    "\n",
    "# disp4 SKU4\n",
    "B5_mu_D4_4 = results_4_opt.params[5]                 # coefficient from regression\n",
    "\n",
    "# feat4 SKU4\n",
    "B6_mu_F4_4 = results_4_opt.params[6]                 # coefficient from regression\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# Set up random draw parameters for coefficients - SKU5 (Sales)\n",
    "\n",
    "# intercept \n",
    "intercept_mu_5    = results_5_opt.params[0]          # coefficient from regression\n",
    "intercept_sigma_5 = results_5_opt.bse[0]/d_sigma     # standard error from regression\n",
    "\n",
    "# price SKU2\n",
    "B1_mu_P2_5    = results_5_opt.params[1]              # coefficient from regression\n",
    "B1_sigma_P2_5 = results_5_opt.bse[1]/d_sigma         # standard error from regression\n",
    "\n",
    "# price SKU3\n",
    "B2_mu_P3_5    = results_5_opt.params[2]              # coefficient from regression\n",
    "B2_sigma_P3_5 = results_5_opt.bse[2]/d_sigma         # standard error from regression\n",
    "\n",
    "# price SKU4\n",
    "B3_mu_P4_5    = results_5_opt.params[3]              # coefficient from regression\n",
    "B3_sigma_P4_5 = results_5_opt.bse[3]/d_sigma             # standard error from regression\n",
    "\n",
    "# price SKU5\n",
    "B4_mu_P5_5    = results_5_opt.params[4]              # coefficient from regression\n",
    "B4_sigma_P5_5 = results_5_opt.bse[4]/d_sigma         # standard error from regression\n",
    "\n",
    "# disp SKU5\n",
    "B5_mu_D5_5    = results_5_opt.params[5]              # coefficient from regression\n",
    "\n",
    "# feat5 SKU5\n",
    "B6_mu_F5_5    = results_5_opt.params[6]              # coefficient from regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Price & Marketing Settings Read and Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T01:22:17.992706Z",
     "start_time": "2021-04-01T01:22:16.584Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "all_settings = pd.read_csv('settings2.csv')\n",
    "\n",
    "Top50 = all_settings.iloc[:2500,:] #jack \n",
    "#Bottom50 = all_settings.iloc[2500:,:] #max\n",
    "\n",
    "settings50 = Top50 \n",
    "#settings50 = Bottom50\n",
    "\n",
    "df_1 = settings50.iloc[:500,:]\n",
    "df_2 = settings50.iloc[500:1000,:]\n",
    "df_3 = settings50.iloc[1000:1500,:]\n",
    "df_4 = settings50.iloc[1500:2000,:]\n",
    "df_5 = settings50.iloc[2000:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T01:22:17.993535Z",
     "start_time": "2021-04-01T01:22:16.586Z"
    }
   },
   "outputs": [],
   "source": [
    "price_msettings_df = df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T01:22:17.994369Z",
     "start_time": "2021-04-01T01:22:16.588Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Monte Carlo Simulation\n",
    "\n",
    "# (Re-) Setting Seed, due to np limitations\n",
    "np.random.seed(42)\n",
    "\n",
    "# Number of simulations per combinations of prices across SKUs'\n",
    "number_sims = 100_000\n",
    "\n",
    "# Store results from each simulation here\n",
    "final_stats = []\n",
    "\n",
    "# Loop over price dataframe\n",
    "for i in tqdm(range(len(price_msettings_df))):\n",
    "    \n",
    "    # Extract price per SKU as log\n",
    "    P_1 = np.log(price_msettings_df.iloc[i, 0])\n",
    "    P_2 = np.log(price_msettings_df.iloc[i, 1])\n",
    "    P_3 = np.log(price_msettings_df.iloc[i, 2])\n",
    "    P_4 = np.log(price_msettings_df.iloc[i, 3])\n",
    "    P_5 = np.log(price_msettings_df.iloc[i, 4])\n",
    "    \n",
    "    # Extract marketing settings per SKU \n",
    "    disp1 = price_msettings_df.iloc[i, 5]\n",
    "    disp2 = price_msettings_df.iloc[i, 6]\n",
    "    disp3 = price_msettings_df.iloc[i, 7]\n",
    "    disp4 = price_msettings_df.iloc[i, 8]\n",
    "    disp5 = price_msettings_df.iloc[i, 9]\n",
    "    \n",
    "    feat1 = price_msettings_df.iloc[i, 10]\n",
    "    feat2 = price_msettings_df.iloc[i, 11]\n",
    "    feat3 = price_msettings_df.iloc[i, 12]\n",
    "    feat4 = price_msettings_df.iloc[i, 13]\n",
    "    feat5 = price_msettings_df.iloc[i, 14]\n",
    "    \n",
    "    # Placeholder\n",
    "    all_stats = []\n",
    "\n",
    "    # Begin Simulation Loop\n",
    "    for i in range(number_sims):\n",
    "        \n",
    "        ###########\n",
    "        #  SKU1   # \n",
    "        ###########\n",
    "        \n",
    "        # Sales\n",
    "        intercept_1 = np.random.normal(intercept_mu_1, intercept_sigma_1)\n",
    "        B1_1   = np.random.normal(B1_mu_P1_1, B1_sigma_P1_1)\n",
    "        B2_1   = np.random.normal(B2_mu_P3_1, B2_sigma_P3_1)\n",
    "        \n",
    "        sales_1 = np.exp(intercept_1 \\\n",
    "                + B1_1 * P_1 \\\n",
    "                + B2_1 * P_3 \\\n",
    "                + B3_mu_D1_1 * disp1 \\\n",
    "                + B4_mu_F1_1 * feat1)\n",
    "        \n",
    "        # Gross Margin\n",
    "        intercept_GR1 = np.random.normal(intercept_mu_GR1, intercept_sigma_GR1)\n",
    "        B1_GR1   = np.random.normal(B1_mu_GR1, B1_sigma_GR1)\n",
    "        \n",
    "        grmar_1 = intercept_GR1 + B1_GR1 * P_1\n",
    "        \n",
    "        # Profit\n",
    "        revenue_1 = sales_1 * oz_1 * np.exp(P_1)\n",
    "        profits_1 = revenue_1 * grmar_1\n",
    "        \n",
    "        \n",
    "        ###########\n",
    "        #  SKU2   # \n",
    "        ###########\n",
    "\n",
    "        # Sales\n",
    "        intercept_2 = np.random.normal(intercept_mu_2, intercept_sigma_2)\n",
    "        B1_2   = np.random.normal(B1_mu_P1_2, B1_sigma_P1_2)\n",
    "        B2_2   = np.random.normal(B2_mu_P2_2, B2_sigma_P2_2)   \n",
    "        \n",
    "        sales_2 = np.exp(intercept_2 \\\n",
    "                + B1_2 * P_1 \\\n",
    "                + B2_2 * P_2 \\\n",
    "                + B3_mu_D2_2 * disp2 \\\n",
    "                + B4_mu_F2_2 * feat2)\n",
    "        \n",
    "        # Gross Margin\n",
    "        intercept_GR2 = np.random.normal(intercept_mu_GR2, intercept_sigma_GR2)\n",
    "        B1_GR2   = np.random.normal(B1_mu_GR2, B1_sigma_GR2)\n",
    "        \n",
    "        grmar_2 = intercept_GR2 + B1_GR2 * P_2\n",
    "        \n",
    "        # Profit\n",
    "        revenue_2 = sales_2 * oz_2 * np.exp(P_2)\n",
    "        profits_2 = revenue_2 * grmar_2\n",
    "        \n",
    "                \n",
    "        ###########\n",
    "        #  SKU3   # \n",
    "        ###########\n",
    "        \n",
    "        # Sales\n",
    "        intercept_3 = np.random.normal(intercept_mu_3, intercept_sigma_3)\n",
    "        B1_3   = np.random.normal(B1_mu_P1_3, B1_sigma_P1_3)\n",
    "        B2_3   = np.random.normal(B2_mu_P3_3, B2_sigma_P3_3)   \n",
    "        B3_3   = np.random.normal(B3_mu_P4_3, B3_sigma_P4_3) \n",
    "\n",
    "        sales_3 = np.exp(intercept_3 \\\n",
    "                + B1_3 * P_1 \\\n",
    "                + B2_3 * P_3 \\\n",
    "                + B3_3 * P_4 \\\n",
    "                + B4_mu_D3_3 * disp3 \\\n",
    "                + B5_mu_F3_3 * feat3)\n",
    "        \n",
    "        # Gross Margin\n",
    "        intercept_GR3 = np.random.normal(intercept_mu_GR3, intercept_sigma_GR3)\n",
    "        B1_GR3   = np.random.normal(B1_mu_GR3, B1_sigma_GR3)\n",
    "        \n",
    "        grmar_3 = intercept_GR3 + B1_GR3 * P_3\n",
    "        \n",
    "        # Profit\n",
    "        revenue_3 = sales_3 * oz_3 * np.exp(P_3)\n",
    "        profits_3 = revenue_3 * grmar_3\n",
    "        \n",
    "        \n",
    "        ###########\n",
    "        #  SKU4   # \n",
    "        ###########\n",
    "        \n",
    "        # Sales\n",
    "        intercept_4 = np.random.normal(intercept_mu_4, intercept_sigma_4)\n",
    "        B1_4   = np.random.normal(B1_mu_P1_4, B1_sigma_P1_4)\n",
    "        B2_4   = np.random.normal(B2_mu_P3_4, B2_sigma_P3_4)   \n",
    "        B3_4   = np.random.normal(B3_mu_P4_4, B3_sigma_P4_4) \n",
    "        B4_4   = np.random.normal(B4_mu_P5_4, B4_sigma_P5_4)\n",
    "        \n",
    "        sales_4 = np.exp(intercept_4 \\\n",
    "                + B1_4 * P_1 \\\n",
    "                + B2_4 * P_3 \\\n",
    "                + B3_4 * P_4 \\\n",
    "                + B4_4 * P_5 \\\n",
    "                + B5_mu_D4_4 * disp4 \\\n",
    "                + B6_mu_F4_4 * feat4)\n",
    "        \n",
    "        # Gross Margin\n",
    "        intercept_GR4 = np.random.normal(intercept_mu_GR4, intercept_sigma_GR4)\n",
    "        B1_GR4   = np.random.normal(B1_mu_GR4, B1_sigma_GR4)\n",
    "        \n",
    "        grmar_4 = intercept_GR4 + B1_GR4 * P_4\n",
    "        \n",
    "        # Profit\n",
    "        revenue_4 = sales_4 * oz_4 * np.exp(P_4)\n",
    "        profits_4 = revenue_4 * grmar_4\n",
    "        \n",
    "        \n",
    "        ###########\n",
    "        #  SKU5   # \n",
    "        ###########\n",
    "        \n",
    "        # Sales\n",
    "        intercept_5 = np.random.normal(intercept_mu_5, intercept_sigma_5)\n",
    "        B1_5   = np.random.normal(B1_mu_P2_5, B1_sigma_P2_5)\n",
    "        B2_5   = np.random.normal(B2_mu_P3_5, B2_sigma_P3_5)   \n",
    "        B3_5   = np.random.normal(B3_mu_P4_5, B3_sigma_P4_5) \n",
    "        B4_5   = np.random.normal(B4_mu_P5_5, B4_sigma_P5_5) \n",
    "        \n",
    "        sales_5 = np.exp(intercept_5 \\\n",
    "                + B1_5 * P_2 \\\n",
    "                + B2_5 * P_3 \\\n",
    "                + B3_5 * P_4 \\\n",
    "                + B4_5 * P_5 \\\n",
    "                + B5_mu_D5_5 * disp5 \\\n",
    "                + B6_mu_F5_5 * feat5)\n",
    "        \n",
    "        # Gross Margin\n",
    "        intercept_GR5 = np.random.normal(intercept_mu_GR5, intercept_sigma_GR5)\n",
    "        B1_GR5   = np.random.normal(B1_mu_GR5, B1_sigma_GR5)\n",
    "        \n",
    "        grmar_5 = intercept_GR5 + B1_GR5 * P_5\n",
    "        \n",
    "        # Profit\n",
    "        revenue_5 = sales_5 * oz_5 * np.exp(P_5)\n",
    "        profits_5 = revenue_5 * grmar_5\n",
    "        \n",
    "        \n",
    "        ####################\n",
    "        #  Appending SKUs  # \n",
    "        ####################\n",
    "        \n",
    "        all_stats.append([sales_1, revenue_1, profits_1, grmar_1,\n",
    "                          sales_2, revenue_2, profits_2, grmar_2,\n",
    "                          sales_3, revenue_3, profits_3, grmar_3,\n",
    "                          sales_4, revenue_4, profits_4, grmar_4,\n",
    "                          sales_5, revenue_5, profits_5, grmar_5])\n",
    "    \n",
    "    results_df = pd.DataFrame.from_records(all_stats,  columns = \n",
    "    ['units_sold_1','revenue_1','profits_1', 'grmar_1',\n",
    "     'units_sold_2','revenue_2','profits_2', 'grmar_2',\n",
    "     'units_sold_3','revenue_3','profits_3', 'grmar_3',\n",
    "     'units_sold_4','revenue_4','profits_4', 'grmar_4',\n",
    "     'units_sold_5','revenue_5','profits_5', 'grmar_5',])\n",
    "        \n",
    "    final_stats.append([np.exp(P_1), np.exp(P_2), np.exp(P_3),\n",
    "                        np.exp(P_4), np.exp(P_5),\n",
    "                        results_df['units_sold_1'].mean(),\n",
    "                        results_df['units_sold_2'].mean(),\n",
    "                        results_df['units_sold_3'].mean(),\n",
    "                        results_df['units_sold_4'].mean(),\n",
    "                        results_df['units_sold_5'].mean(),\n",
    "                        results_df['grmar_1'].mean(),\n",
    "                        results_df['grmar_2'].mean(),\n",
    "                        results_df['grmar_3'].mean(),\n",
    "                        results_df['grmar_4'].mean(),\n",
    "                        results_df['grmar_5'].mean(),\n",
    "                        results_df['profits_1'].mean(),\n",
    "                        results_df['profits_2'].mean(),\n",
    "                        results_df['profits_3'].mean(),\n",
    "                        results_df['profits_4'].mean(),\n",
    "                        results_df['profits_5'].mean(),\n",
    "                        feat1,feat2,feat3,feat4,feat5,\n",
    "                        disp1,disp2,disp3,disp4,disp5])\n",
    "    \n",
    "final_stats_df = pd.DataFrame.from_records(final_stats, columns =\n",
    "                ['Price per Oz_1', 'Price per Oz_2',\n",
    "                 'Price per Oz_3', 'Price per Oz_4', 'Price per Oz_5',\n",
    "                 'Sales_1', 'Sales_2', 'Sales_3', 'Sales_4', 'Sales_5',\n",
    "                 'GrMar_1', 'GrMar_2', 'GrMar_3', 'GrMar_4', 'GrMar_5',\n",
    "                 'Profits_1', 'Profits_2', \n",
    "                 'Profits_3', 'Profits_4', 'Profits_5',\n",
    "                 'Feat_1', 'Feat_2', 'Feat_3', 'Feat_4', 'Feat_5',\n",
    "                 'Disp_1', 'Disp_2', 'Disp_3', 'Disp_4', 'Disp_5'])\n",
    "\n",
    "final_stats_df['Total Profits'] = final_stats_df['Profits_5']\\\n",
    "                                + final_stats_df['Profits_4']\\\n",
    "                                + final_stats_df['Profits_3']\\\n",
    "                                + final_stats_df['Profits_2']\\\n",
    "                                + final_stats_df['Profits_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T01:22:17.995152Z",
     "start_time": "2021-04-01T01:22:16.590Z"
    }
   },
   "outputs": [],
   "source": [
    "df_1_stats = final_stats_df \n",
    "df_1_stats.to_csv('df_1_stats.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T01:22:17.995959Z",
     "start_time": "2021-04-01T01:22:16.592Z"
    }
   },
   "outputs": [],
   "source": [
    "price_msettings_df = df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T01:22:17.996781Z",
     "start_time": "2021-04-01T01:22:16.594Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Monte Carlo Simulation\n",
    "\n",
    "# (Re-) Setting Seed, due to np limitations\n",
    "np.random.seed(42)\n",
    "\n",
    "# Number of simulations per combinations of prices across SKUs'\n",
    "number_sims = 100_000\n",
    "\n",
    "# Store results from each simulation here\n",
    "final_stats = []\n",
    "\n",
    "# Loop over price dataframe\n",
    "for i in tqdm(range(len(price_msettings_df))):\n",
    "    \n",
    "    # Extract price per SKU as log\n",
    "    P_1 = np.log(price_msettings_df.iloc[i, 0])\n",
    "    P_2 = np.log(price_msettings_df.iloc[i, 1])\n",
    "    P_3 = np.log(price_msettings_df.iloc[i, 2])\n",
    "    P_4 = np.log(price_msettings_df.iloc[i, 3])\n",
    "    P_5 = np.log(price_msettings_df.iloc[i, 4])\n",
    "    \n",
    "    # Extract marketing settings per SKU \n",
    "    disp1 = price_msettings_df.iloc[i, 5]\n",
    "    disp2 = price_msettings_df.iloc[i, 6]\n",
    "    disp3 = price_msettings_df.iloc[i, 7]\n",
    "    disp4 = price_msettings_df.iloc[i, 8]\n",
    "    disp5 = price_msettings_df.iloc[i, 9]\n",
    "    \n",
    "    feat1 = price_msettings_df.iloc[i, 10]\n",
    "    feat2 = price_msettings_df.iloc[i, 11]\n",
    "    feat3 = price_msettings_df.iloc[i, 12]\n",
    "    feat4 = price_msettings_df.iloc[i, 13]\n",
    "    feat5 = price_msettings_df.iloc[i, 14]\n",
    "    \n",
    "    # Placeholder\n",
    "    all_stats = []\n",
    "\n",
    "    # Begin Simulation Loop\n",
    "    for i in range(number_sims):\n",
    "        \n",
    "        ###########\n",
    "        #  SKU1   # \n",
    "        ###########\n",
    "        \n",
    "        # Sales\n",
    "        intercept_1 = np.random.normal(intercept_mu_1, intercept_sigma_1)\n",
    "        B1_1   = np.random.normal(B1_mu_P1_1, B1_sigma_P1_1)\n",
    "        B2_1   = np.random.normal(B2_mu_P3_1, B2_sigma_P3_1)\n",
    "        \n",
    "        sales_1 = np.exp(intercept_1 \\\n",
    "                + B1_1 * P_1 \\\n",
    "                + B2_1 * P_3 \\\n",
    "                + B3_mu_D1_1 * disp1 \\\n",
    "                + B4_mu_F1_1 * feat1)\n",
    "        \n",
    "        # Gross Margin\n",
    "        intercept_GR1 = np.random.normal(intercept_mu_GR1, intercept_sigma_GR1)\n",
    "        B1_GR1   = np.random.normal(B1_mu_GR1, B1_sigma_GR1)\n",
    "        \n",
    "        grmar_1 = intercept_GR1 + B1_GR1 * P_1\n",
    "        \n",
    "        # Profit\n",
    "        revenue_1 = sales_1 * oz_1 * np.exp(P_1)\n",
    "        profits_1 = revenue_1 * grmar_1\n",
    "        \n",
    "        \n",
    "        ###########\n",
    "        #  SKU2   # \n",
    "        ###########\n",
    "\n",
    "        # Sales\n",
    "        intercept_2 = np.random.normal(intercept_mu_2, intercept_sigma_2)\n",
    "        B1_2   = np.random.normal(B1_mu_P1_2, B1_sigma_P1_2)\n",
    "        B2_2   = np.random.normal(B2_mu_P2_2, B2_sigma_P2_2)   \n",
    "        \n",
    "        sales_2 = np.exp(intercept_2 \\\n",
    "                + B1_2 * P_1 \\\n",
    "                + B2_2 * P_2 \\\n",
    "                + B3_mu_D2_2 * disp2 \\\n",
    "                + B4_mu_F2_2 * feat2)\n",
    "        \n",
    "        # Gross Margin\n",
    "        intercept_GR2 = np.random.normal(intercept_mu_GR2, intercept_sigma_GR2)\n",
    "        B1_GR2   = np.random.normal(B1_mu_GR2, B1_sigma_GR2)\n",
    "        \n",
    "        grmar_2 = intercept_GR2 + B1_GR2 * P_2\n",
    "        \n",
    "        # Profit\n",
    "        revenue_2 = sales_2 * oz_2 * np.exp(P_2)\n",
    "        profits_2 = revenue_2 * grmar_2\n",
    "        \n",
    "                \n",
    "        ###########\n",
    "        #  SKU3   # \n",
    "        ###########\n",
    "        \n",
    "        # Sales\n",
    "        intercept_3 = np.random.normal(intercept_mu_3, intercept_sigma_3)\n",
    "        B1_3   = np.random.normal(B1_mu_P1_3, B1_sigma_P1_3)\n",
    "        B2_3   = np.random.normal(B2_mu_P3_3, B2_sigma_P3_3)   \n",
    "        B3_3   = np.random.normal(B3_mu_P4_3, B3_sigma_P4_3) \n",
    "\n",
    "        sales_3 = np.exp(intercept_3 \\\n",
    "                + B1_3 * P_1 \\\n",
    "                + B2_3 * P_3 \\\n",
    "                + B3_3 * P_4 \\\n",
    "                + B4_mu_D3_3 * disp3 \\\n",
    "                + B5_mu_F3_3 * feat3)\n",
    "        \n",
    "        # Gross Margin\n",
    "        intercept_GR3 = np.random.normal(intercept_mu_GR3, intercept_sigma_GR3)\n",
    "        B1_GR3   = np.random.normal(B1_mu_GR3, B1_sigma_GR3)\n",
    "        \n",
    "        grmar_3 = intercept_GR3 + B1_GR3 * P_3\n",
    "        \n",
    "        # Profit\n",
    "        revenue_3 = sales_3 * oz_3 * np.exp(P_3)\n",
    "        profits_3 = revenue_3 * grmar_3\n",
    "        \n",
    "        \n",
    "        ###########\n",
    "        #  SKU4   # \n",
    "        ###########\n",
    "        \n",
    "        # Sales\n",
    "        intercept_4 = np.random.normal(intercept_mu_4, intercept_sigma_4)\n",
    "        B1_4   = np.random.normal(B1_mu_P1_4, B1_sigma_P1_4)\n",
    "        B2_4   = np.random.normal(B2_mu_P3_4, B2_sigma_P3_4)   \n",
    "        B3_4   = np.random.normal(B3_mu_P4_4, B3_sigma_P4_4) \n",
    "        B4_4   = np.random.normal(B4_mu_P5_4, B4_sigma_P5_4)\n",
    "        \n",
    "        sales_4 = np.exp(intercept_4 \\\n",
    "                + B1_4 * P_1 \\\n",
    "                + B2_4 * P_3 \\\n",
    "                + B3_4 * P_4 \\\n",
    "                + B4_4 * P_5 \\\n",
    "                + B5_mu_D4_4 * disp4 \\\n",
    "                + B6_mu_F4_4 * feat4)\n",
    "        \n",
    "        # Gross Margin\n",
    "        intercept_GR4 = np.random.normal(intercept_mu_GR4, intercept_sigma_GR4)\n",
    "        B1_GR4   = np.random.normal(B1_mu_GR4, B1_sigma_GR4)\n",
    "        \n",
    "        grmar_4 = intercept_GR4 + B1_GR4 * P_4\n",
    "        \n",
    "        # Profit\n",
    "        revenue_4 = sales_4 * oz_4 * np.exp(P_4)\n",
    "        profits_4 = revenue_4 * grmar_4\n",
    "        \n",
    "        \n",
    "        ###########\n",
    "        #  SKU5   # \n",
    "        ###########\n",
    "        \n",
    "        # Sales\n",
    "        intercept_5 = np.random.normal(intercept_mu_5, intercept_sigma_5)\n",
    "        B1_5   = np.random.normal(B1_mu_P2_5, B1_sigma_P2_5)\n",
    "        B2_5   = np.random.normal(B2_mu_P3_5, B2_sigma_P3_5)   \n",
    "        B3_5   = np.random.normal(B3_mu_P4_5, B3_sigma_P4_5) \n",
    "        B4_5   = np.random.normal(B4_mu_P5_5, B4_sigma_P5_5) \n",
    "        \n",
    "        sales_5 = np.exp(intercept_5 \\\n",
    "                + B1_5 * P_2 \\\n",
    "                + B2_5 * P_3 \\\n",
    "                + B3_5 * P_4 \\\n",
    "                + B4_5 * P_5 \\\n",
    "                + B5_mu_D5_5 * disp5 \\\n",
    "                + B6_mu_F5_5 * feat5)\n",
    "        \n",
    "        # Gross Margin\n",
    "        intercept_GR5 = np.random.normal(intercept_mu_GR5, intercept_sigma_GR5)\n",
    "        B1_GR5   = np.random.normal(B1_mu_GR5, B1_sigma_GR5)\n",
    "        \n",
    "        grmar_5 = intercept_GR5 + B1_GR5 * P_5\n",
    "        \n",
    "        # Profit\n",
    "        revenue_5 = sales_5 * oz_5 * np.exp(P_5)\n",
    "        profits_5 = revenue_5 * grmar_5\n",
    "        \n",
    "        \n",
    "        ####################\n",
    "        #  Appending SKUs  # \n",
    "        ####################\n",
    "        \n",
    "        all_stats.append([sales_1, revenue_1, profits_1, grmar_1,\n",
    "                          sales_2, revenue_2, profits_2, grmar_2,\n",
    "                          sales_3, revenue_3, profits_3, grmar_3,\n",
    "                          sales_4, revenue_4, profits_4, grmar_4,\n",
    "                          sales_5, revenue_5, profits_5, grmar_5])\n",
    "    \n",
    "    results_df = pd.DataFrame.from_records(all_stats,  columns = \n",
    "    ['units_sold_1','revenue_1','profits_1', 'grmar_1',\n",
    "     'units_sold_2','revenue_2','profits_2', 'grmar_2',\n",
    "     'units_sold_3','revenue_3','profits_3', 'grmar_3',\n",
    "     'units_sold_4','revenue_4','profits_4', 'grmar_4',\n",
    "     'units_sold_5','revenue_5','profits_5', 'grmar_5',])\n",
    "        \n",
    "    final_stats.append([np.exp(P_1), np.exp(P_2), np.exp(P_3),\n",
    "                        np.exp(P_4), np.exp(P_5),\n",
    "                        results_df['units_sold_1'].mean(),\n",
    "                        results_df['units_sold_2'].mean(),\n",
    "                        results_df['units_sold_3'].mean(),\n",
    "                        results_df['units_sold_4'].mean(),\n",
    "                        results_df['units_sold_5'].mean(),\n",
    "                        results_df['grmar_1'].mean(),\n",
    "                        results_df['grmar_2'].mean(),\n",
    "                        results_df['grmar_3'].mean(),\n",
    "                        results_df['grmar_4'].mean(),\n",
    "                        results_df['grmar_5'].mean(),\n",
    "                        results_df['profits_1'].mean(),\n",
    "                        results_df['profits_2'].mean(),\n",
    "                        results_df['profits_3'].mean(),\n",
    "                        results_df['profits_4'].mean(),\n",
    "                        results_df['profits_5'].mean(),\n",
    "                        feat1,feat2,feat3,feat4,feat5,\n",
    "                        disp1,disp2,disp3,disp4,disp5])\n",
    "    \n",
    "final_stats_df = pd.DataFrame.from_records(final_stats, columns =\n",
    "                ['Price per Oz_1', 'Price per Oz_2',\n",
    "                 'Price per Oz_3', 'Price per Oz_4', 'Price per Oz_5',\n",
    "                 'Sales_1', 'Sales_2', 'Sales_3', 'Sales_4', 'Sales_5',\n",
    "                 'GrMar_1', 'GrMar_2', 'GrMar_3', 'GrMar_4', 'GrMar_5',\n",
    "                 'Profits_1', 'Profits_2', \n",
    "                 'Profits_3', 'Profits_4', 'Profits_5',\n",
    "                 'Feat_1', 'Feat_2', 'Feat_3', 'Feat_4', 'Feat_5',\n",
    "                 'Disp_1', 'Disp_2', 'Disp_3', 'Disp_4', 'Disp_5'])\n",
    "\n",
    "final_stats_df['Total Profits'] = final_stats_df['Profits_5']\\\n",
    "                                + final_stats_df['Profits_4']\\\n",
    "                                + final_stats_df['Profits_3']\\\n",
    "                                + final_stats_df['Profits_2']\\\n",
    "                                + final_stats_df['Profits_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T01:22:17.997577Z",
     "start_time": "2021-04-01T01:22:16.597Z"
    }
   },
   "outputs": [],
   "source": [
    "df_2_stats = final_stats_df \n",
    "df_2_stats.to_csv('df_2_stats.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T01:22:17.998330Z",
     "start_time": "2021-04-01T01:22:16.598Z"
    }
   },
   "outputs": [],
   "source": [
    "price_msettings_df = df_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T01:22:17.999187Z",
     "start_time": "2021-04-01T01:22:16.600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Monte Carlo Simulation\n",
    "\n",
    "# (Re-) Setting Seed, due to np limitations\n",
    "np.random.seed(42)\n",
    "\n",
    "# Number of simulations per combinations of prices across SKUs'\n",
    "number_sims = 100_000\n",
    "\n",
    "# Store results from each simulation here\n",
    "final_stats = []\n",
    "\n",
    "# Loop over price dataframe\n",
    "for i in tqdm(range(len(price_msettings_df))):\n",
    "    \n",
    "    # Extract price per SKU as log\n",
    "    P_1 = np.log(price_msettings_df.iloc[i, 0])\n",
    "    P_2 = np.log(price_msettings_df.iloc[i, 1])\n",
    "    P_3 = np.log(price_msettings_df.iloc[i, 2])\n",
    "    P_4 = np.log(price_msettings_df.iloc[i, 3])\n",
    "    P_5 = np.log(price_msettings_df.iloc[i, 4])\n",
    "    \n",
    "    # Extract marketing settings per SKU \n",
    "    disp1 = price_msettings_df.iloc[i, 5]\n",
    "    disp2 = price_msettings_df.iloc[i, 6]\n",
    "    disp3 = price_msettings_df.iloc[i, 7]\n",
    "    disp4 = price_msettings_df.iloc[i, 8]\n",
    "    disp5 = price_msettings_df.iloc[i, 9]\n",
    "    \n",
    "    feat1 = price_msettings_df.iloc[i, 10]\n",
    "    feat2 = price_msettings_df.iloc[i, 11]\n",
    "    feat3 = price_msettings_df.iloc[i, 12]\n",
    "    feat4 = price_msettings_df.iloc[i, 13]\n",
    "    feat5 = price_msettings_df.iloc[i, 14]\n",
    "    \n",
    "    # Placeholder\n",
    "    all_stats = []\n",
    "\n",
    "    # Begin Simulation Loop\n",
    "    for i in range(number_sims):\n",
    "        \n",
    "        ###########\n",
    "        #  SKU1   # \n",
    "        ###########\n",
    "        \n",
    "        # Sales\n",
    "        intercept_1 = np.random.normal(intercept_mu_1, intercept_sigma_1)\n",
    "        B1_1   = np.random.normal(B1_mu_P1_1, B1_sigma_P1_1)\n",
    "        B2_1   = np.random.normal(B2_mu_P3_1, B2_sigma_P3_1)\n",
    "        \n",
    "        sales_1 = np.exp(intercept_1 \\\n",
    "                + B1_1 * P_1 \\\n",
    "                + B2_1 * P_3 \\\n",
    "                + B3_mu_D1_1 * disp1 \\\n",
    "                + B4_mu_F1_1 * feat1)\n",
    "        \n",
    "        # Gross Margin\n",
    "        intercept_GR1 = np.random.normal(intercept_mu_GR1, intercept_sigma_GR1)\n",
    "        B1_GR1   = np.random.normal(B1_mu_GR1, B1_sigma_GR1)\n",
    "        \n",
    "        grmar_1 = intercept_GR1 + B1_GR1 * P_1\n",
    "        \n",
    "        # Profit\n",
    "        revenue_1 = sales_1 * oz_1 * np.exp(P_1)\n",
    "        profits_1 = revenue_1 * grmar_1\n",
    "        \n",
    "        \n",
    "        ###########\n",
    "        #  SKU2   # \n",
    "        ###########\n",
    "\n",
    "        # Sales\n",
    "        intercept_2 = np.random.normal(intercept_mu_2, intercept_sigma_2)\n",
    "        B1_2   = np.random.normal(B1_mu_P1_2, B1_sigma_P1_2)\n",
    "        B2_2   = np.random.normal(B2_mu_P2_2, B2_sigma_P2_2)   \n",
    "        \n",
    "        sales_2 = np.exp(intercept_2 \\\n",
    "                + B1_2 * P_1 \\\n",
    "                + B2_2 * P_2 \\\n",
    "                + B3_mu_D2_2 * disp2 \\\n",
    "                + B4_mu_F2_2 * feat2)\n",
    "        \n",
    "        # Gross Margin\n",
    "        intercept_GR2 = np.random.normal(intercept_mu_GR2, intercept_sigma_GR2)\n",
    "        B1_GR2   = np.random.normal(B1_mu_GR2, B1_sigma_GR2)\n",
    "        \n",
    "        grmar_2 = intercept_GR2 + B1_GR2 * P_2\n",
    "        \n",
    "        # Profit\n",
    "        revenue_2 = sales_2 * oz_2 * np.exp(P_2)\n",
    "        profits_2 = revenue_2 * grmar_2\n",
    "        \n",
    "                \n",
    "        ###########\n",
    "        #  SKU3   # \n",
    "        ###########\n",
    "        \n",
    "        # Sales\n",
    "        intercept_3 = np.random.normal(intercept_mu_3, intercept_sigma_3)\n",
    "        B1_3   = np.random.normal(B1_mu_P1_3, B1_sigma_P1_3)\n",
    "        B2_3   = np.random.normal(B2_mu_P3_3, B2_sigma_P3_3)   \n",
    "        B3_3   = np.random.normal(B3_mu_P4_3, B3_sigma_P4_3) \n",
    "\n",
    "        sales_3 = np.exp(intercept_3 \\\n",
    "                + B1_3 * P_1 \\\n",
    "                + B2_3 * P_3 \\\n",
    "                + B3_3 * P_4 \\\n",
    "                + B4_mu_D3_3 * disp3 \\\n",
    "                + B5_mu_F3_3 * feat3)\n",
    "        \n",
    "        # Gross Margin\n",
    "        intercept_GR3 = np.random.normal(intercept_mu_GR3, intercept_sigma_GR3)\n",
    "        B1_GR3   = np.random.normal(B1_mu_GR3, B1_sigma_GR3)\n",
    "        \n",
    "        grmar_3 = intercept_GR3 + B1_GR3 * P_3\n",
    "        \n",
    "        # Profit\n",
    "        revenue_3 = sales_3 * oz_3 * np.exp(P_3)\n",
    "        profits_3 = revenue_3 * grmar_3\n",
    "        \n",
    "        \n",
    "        ###########\n",
    "        #  SKU4   # \n",
    "        ###########\n",
    "        \n",
    "        # Sales\n",
    "        intercept_4 = np.random.normal(intercept_mu_4, intercept_sigma_4)\n",
    "        B1_4   = np.random.normal(B1_mu_P1_4, B1_sigma_P1_4)\n",
    "        B2_4   = np.random.normal(B2_mu_P3_4, B2_sigma_P3_4)   \n",
    "        B3_4   = np.random.normal(B3_mu_P4_4, B3_sigma_P4_4) \n",
    "        B4_4   = np.random.normal(B4_mu_P5_4, B4_sigma_P5_4)\n",
    "        \n",
    "        sales_4 = np.exp(intercept_4 \\\n",
    "                + B1_4 * P_1 \\\n",
    "                + B2_4 * P_3 \\\n",
    "                + B3_4 * P_4 \\\n",
    "                + B4_4 * P_5 \\\n",
    "                + B5_mu_D4_4 * disp4 \\\n",
    "                + B6_mu_F4_4 * feat4)\n",
    "        \n",
    "        # Gross Margin\n",
    "        intercept_GR4 = np.random.normal(intercept_mu_GR4, intercept_sigma_GR4)\n",
    "        B1_GR4   = np.random.normal(B1_mu_GR4, B1_sigma_GR4)\n",
    "        \n",
    "        grmar_4 = intercept_GR4 + B1_GR4 * P_4\n",
    "        \n",
    "        # Profit\n",
    "        revenue_4 = sales_4 * oz_4 * np.exp(P_4)\n",
    "        profits_4 = revenue_4 * grmar_4\n",
    "        \n",
    "        \n",
    "        ###########\n",
    "        #  SKU5   # \n",
    "        ###########\n",
    "        \n",
    "        # Sales\n",
    "        intercept_5 = np.random.normal(intercept_mu_5, intercept_sigma_5)\n",
    "        B1_5   = np.random.normal(B1_mu_P2_5, B1_sigma_P2_5)\n",
    "        B2_5   = np.random.normal(B2_mu_P3_5, B2_sigma_P3_5)   \n",
    "        B3_5   = np.random.normal(B3_mu_P4_5, B3_sigma_P4_5) \n",
    "        B4_5   = np.random.normal(B4_mu_P5_5, B4_sigma_P5_5) \n",
    "        \n",
    "        sales_5 = np.exp(intercept_5 \\\n",
    "                + B1_5 * P_2 \\\n",
    "                + B2_5 * P_3 \\\n",
    "                + B3_5 * P_4 \\\n",
    "                + B4_5 * P_5 \\\n",
    "                + B5_mu_D5_5 * disp5 \\\n",
    "                + B6_mu_F5_5 * feat5)\n",
    "        \n",
    "        # Gross Margin\n",
    "        intercept_GR5 = np.random.normal(intercept_mu_GR5, intercept_sigma_GR5)\n",
    "        B1_GR5   = np.random.normal(B1_mu_GR5, B1_sigma_GR5)\n",
    "        \n",
    "        grmar_5 = intercept_GR5 + B1_GR5 * P_5\n",
    "        \n",
    "        # Profit\n",
    "        revenue_5 = sales_5 * oz_5 * np.exp(P_5)\n",
    "        profits_5 = revenue_5 * grmar_5\n",
    "        \n",
    "        \n",
    "        ####################\n",
    "        #  Appending SKUs  # \n",
    "        ####################\n",
    "        \n",
    "        all_stats.append([sales_1, revenue_1, profits_1, grmar_1,\n",
    "                          sales_2, revenue_2, profits_2, grmar_2,\n",
    "                          sales_3, revenue_3, profits_3, grmar_3,\n",
    "                          sales_4, revenue_4, profits_4, grmar_4,\n",
    "                          sales_5, revenue_5, profits_5, grmar_5])\n",
    "    \n",
    "    results_df = pd.DataFrame.from_records(all_stats,  columns = \n",
    "    ['units_sold_1','revenue_1','profits_1', 'grmar_1',\n",
    "     'units_sold_2','revenue_2','profits_2', 'grmar_2',\n",
    "     'units_sold_3','revenue_3','profits_3', 'grmar_3',\n",
    "     'units_sold_4','revenue_4','profits_4', 'grmar_4',\n",
    "     'units_sold_5','revenue_5','profits_5', 'grmar_5',])\n",
    "        \n",
    "    final_stats.append([np.exp(P_1), np.exp(P_2), np.exp(P_3),\n",
    "                        np.exp(P_4), np.exp(P_5),\n",
    "                        results_df['units_sold_1'].mean(),\n",
    "                        results_df['units_sold_2'].mean(),\n",
    "                        results_df['units_sold_3'].mean(),\n",
    "                        results_df['units_sold_4'].mean(),\n",
    "                        results_df['units_sold_5'].mean(),\n",
    "                        results_df['grmar_1'].mean(),\n",
    "                        results_df['grmar_2'].mean(),\n",
    "                        results_df['grmar_3'].mean(),\n",
    "                        results_df['grmar_4'].mean(),\n",
    "                        results_df['grmar_5'].mean(),\n",
    "                        results_df['profits_1'].mean(),\n",
    "                        results_df['profits_2'].mean(),\n",
    "                        results_df['profits_3'].mean(),\n",
    "                        results_df['profits_4'].mean(),\n",
    "                        results_df['profits_5'].mean(),\n",
    "                        feat1,feat2,feat3,feat4,feat5,\n",
    "                        disp1,disp2,disp3,disp4,disp5])\n",
    "    \n",
    "final_stats_df = pd.DataFrame.from_records(final_stats, columns =\n",
    "                ['Price per Oz_1', 'Price per Oz_2',\n",
    "                 'Price per Oz_3', 'Price per Oz_4', 'Price per Oz_5',\n",
    "                 'Sales_1', 'Sales_2', 'Sales_3', 'Sales_4', 'Sales_5',\n",
    "                 'GrMar_1', 'GrMar_2', 'GrMar_3', 'GrMar_4', 'GrMar_5',\n",
    "                 'Profits_1', 'Profits_2', \n",
    "                 'Profits_3', 'Profits_4', 'Profits_5',\n",
    "                 'Feat_1', 'Feat_2', 'Feat_3', 'Feat_4', 'Feat_5',\n",
    "                 'Disp_1', 'Disp_2', 'Disp_3', 'Disp_4', 'Disp_5'])\n",
    "\n",
    "final_stats_df['Total Profits'] = final_stats_df['Profits_5']\\\n",
    "                                + final_stats_df['Profits_4']\\\n",
    "                                + final_stats_df['Profits_3']\\\n",
    "                                + final_stats_df['Profits_2']\\\n",
    "                                + final_stats_df['Profits_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T01:22:17.999911Z",
     "start_time": "2021-04-01T01:22:16.602Z"
    }
   },
   "outputs": [],
   "source": [
    "df_3_stats = final_stats_df \n",
    "df_3_stats.to_csv('df_3_stats.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T01:22:18.000676Z",
     "start_time": "2021-04-01T01:22:16.604Z"
    }
   },
   "outputs": [],
   "source": [
    "price_msettings_df = df_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T01:22:18.001573Z",
     "start_time": "2021-04-01T01:22:16.606Z"
    }
   },
   "outputs": [],
   "source": [
    "# Monte Carlo Simulation\n",
    "\n",
    "# (Re-) Setting Seed, due to np limitations\n",
    "np.random.seed(42)\n",
    "\n",
    "# Number of simulations per combinations of prices across SKUs'\n",
    "number_sims = 100_000\n",
    "\n",
    "# Store results from each simulation here\n",
    "final_stats = []\n",
    "\n",
    "# Loop over price dataframe\n",
    "for i in tqdm(range(len(price_msettings_df))):\n",
    "    \n",
    "    # Extract price per SKU as log\n",
    "    P_1 = np.log(price_msettings_df.iloc[i, 0])\n",
    "    P_2 = np.log(price_msettings_df.iloc[i, 1])\n",
    "    P_3 = np.log(price_msettings_df.iloc[i, 2])\n",
    "    P_4 = np.log(price_msettings_df.iloc[i, 3])\n",
    "    P_5 = np.log(price_msettings_df.iloc[i, 4])\n",
    "    \n",
    "    # Extract marketing settings per SKU \n",
    "    disp1 = price_msettings_df.iloc[i, 5]\n",
    "    disp2 = price_msettings_df.iloc[i, 6]\n",
    "    disp3 = price_msettings_df.iloc[i, 7]\n",
    "    disp4 = price_msettings_df.iloc[i, 8]\n",
    "    disp5 = price_msettings_df.iloc[i, 9]\n",
    "    \n",
    "    feat1 = price_msettings_df.iloc[i, 10]\n",
    "    feat2 = price_msettings_df.iloc[i, 11]\n",
    "    feat3 = price_msettings_df.iloc[i, 12]\n",
    "    feat4 = price_msettings_df.iloc[i, 13]\n",
    "    feat5 = price_msettings_df.iloc[i, 14]\n",
    "    \n",
    "    # Placeholder\n",
    "    all_stats = []\n",
    "\n",
    "    # Begin Simulation Loop\n",
    "    for i in range(number_sims):\n",
    "        \n",
    "        ###########\n",
    "        #  SKU1   # \n",
    "        ###########\n",
    "        \n",
    "        # Sales\n",
    "        intercept_1 = np.random.normal(intercept_mu_1, intercept_sigma_1)\n",
    "        B1_1   = np.random.normal(B1_mu_P1_1, B1_sigma_P1_1)\n",
    "        B2_1   = np.random.normal(B2_mu_P3_1, B2_sigma_P3_1)\n",
    "        \n",
    "        sales_1 = np.exp(intercept_1 \\\n",
    "                + B1_1 * P_1 \\\n",
    "                + B2_1 * P_3 \\\n",
    "                + B3_mu_D1_1 * disp1 \\\n",
    "                + B4_mu_F1_1 * feat1)\n",
    "        \n",
    "        # Gross Margin\n",
    "        intercept_GR1 = np.random.normal(intercept_mu_GR1, intercept_sigma_GR1)\n",
    "        B1_GR1   = np.random.normal(B1_mu_GR1, B1_sigma_GR1)\n",
    "        \n",
    "        grmar_1 = intercept_GR1 + B1_GR1 * P_1\n",
    "        \n",
    "        # Profit\n",
    "        revenue_1 = sales_1 * oz_1 * np.exp(P_1)\n",
    "        profits_1 = revenue_1 * grmar_1\n",
    "        \n",
    "        \n",
    "        ###########\n",
    "        #  SKU2   # \n",
    "        ###########\n",
    "\n",
    "        # Sales\n",
    "        intercept_2 = np.random.normal(intercept_mu_2, intercept_sigma_2)\n",
    "        B1_2   = np.random.normal(B1_mu_P1_2, B1_sigma_P1_2)\n",
    "        B2_2   = np.random.normal(B2_mu_P2_2, B2_sigma_P2_2)   \n",
    "        \n",
    "        sales_2 = np.exp(intercept_2 \\\n",
    "                + B1_2 * P_1 \\\n",
    "                + B2_2 * P_2 \\\n",
    "                + B3_mu_D2_2 * disp2 \\\n",
    "                + B4_mu_F2_2 * feat2)\n",
    "        \n",
    "        # Gross Margin\n",
    "        intercept_GR2 = np.random.normal(intercept_mu_GR2, intercept_sigma_GR2)\n",
    "        B1_GR2   = np.random.normal(B1_mu_GR2, B1_sigma_GR2)\n",
    "        \n",
    "        grmar_2 = intercept_GR2 + B1_GR2 * P_2\n",
    "        \n",
    "        # Profit\n",
    "        revenue_2 = sales_2 * oz_2 * np.exp(P_2)\n",
    "        profits_2 = revenue_2 * grmar_2\n",
    "        \n",
    "                \n",
    "        ###########\n",
    "        #  SKU3   # \n",
    "        ###########\n",
    "        \n",
    "        # Sales\n",
    "        intercept_3 = np.random.normal(intercept_mu_3, intercept_sigma_3)\n",
    "        B1_3   = np.random.normal(B1_mu_P1_3, B1_sigma_P1_3)\n",
    "        B2_3   = np.random.normal(B2_mu_P3_3, B2_sigma_P3_3)   \n",
    "        B3_3   = np.random.normal(B3_mu_P4_3, B3_sigma_P4_3) \n",
    "\n",
    "        sales_3 = np.exp(intercept_3 \\\n",
    "                + B1_3 * P_1 \\\n",
    "                + B2_3 * P_3 \\\n",
    "                + B3_3 * P_4 \\\n",
    "                + B4_mu_D3_3 * disp3 \\\n",
    "                + B5_mu_F3_3 * feat3)\n",
    "        \n",
    "        # Gross Margin\n",
    "        intercept_GR3 = np.random.normal(intercept_mu_GR3, intercept_sigma_GR3)\n",
    "        B1_GR3   = np.random.normal(B1_mu_GR3, B1_sigma_GR3)\n",
    "        \n",
    "        grmar_3 = intercept_GR3 + B1_GR3 * P_3\n",
    "        \n",
    "        # Profit\n",
    "        revenue_3 = sales_3 * oz_3 * np.exp(P_3)\n",
    "        profits_3 = revenue_3 * grmar_3\n",
    "        \n",
    "        \n",
    "        ###########\n",
    "        #  SKU4   # \n",
    "        ###########\n",
    "        \n",
    "        # Sales\n",
    "        intercept_4 = np.random.normal(intercept_mu_4, intercept_sigma_4)\n",
    "        B1_4   = np.random.normal(B1_mu_P1_4, B1_sigma_P1_4)\n",
    "        B2_4   = np.random.normal(B2_mu_P3_4, B2_sigma_P3_4)   \n",
    "        B3_4   = np.random.normal(B3_mu_P4_4, B3_sigma_P4_4) \n",
    "        B4_4   = np.random.normal(B4_mu_P5_4, B4_sigma_P5_4)\n",
    "        \n",
    "        sales_4 = np.exp(intercept_4 \\\n",
    "                + B1_4 * P_1 \\\n",
    "                + B2_4 * P_3 \\\n",
    "                + B3_4 * P_4 \\\n",
    "                + B4_4 * P_5 \\\n",
    "                + B5_mu_D4_4 * disp4 \\\n",
    "                + B6_mu_F4_4 * feat4)\n",
    "        \n",
    "        # Gross Margin\n",
    "        intercept_GR4 = np.random.normal(intercept_mu_GR4, intercept_sigma_GR4)\n",
    "        B1_GR4   = np.random.normal(B1_mu_GR4, B1_sigma_GR4)\n",
    "        \n",
    "        grmar_4 = intercept_GR4 + B1_GR4 * P_4\n",
    "        \n",
    "        # Profit\n",
    "        revenue_4 = sales_4 * oz_4 * np.exp(P_4)\n",
    "        profits_4 = revenue_4 * grmar_4\n",
    "        \n",
    "        \n",
    "        ###########\n",
    "        #  SKU5   # \n",
    "        ###########\n",
    "        \n",
    "        # Sales\n",
    "        intercept_5 = np.random.normal(intercept_mu_5, intercept_sigma_5)\n",
    "        B1_5   = np.random.normal(B1_mu_P2_5, B1_sigma_P2_5)\n",
    "        B2_5   = np.random.normal(B2_mu_P3_5, B2_sigma_P3_5)   \n",
    "        B3_5   = np.random.normal(B3_mu_P4_5, B3_sigma_P4_5) \n",
    "        B4_5   = np.random.normal(B4_mu_P5_5, B4_sigma_P5_5) \n",
    "        \n",
    "        sales_5 = np.exp(intercept_5 \\\n",
    "                + B1_5 * P_2 \\\n",
    "                + B2_5 * P_3 \\\n",
    "                + B3_5 * P_4 \\\n",
    "                + B4_5 * P_5 \\\n",
    "                + B5_mu_D5_5 * disp5 \\\n",
    "                + B6_mu_F5_5 * feat5)\n",
    "        \n",
    "        # Gross Margin\n",
    "        intercept_GR5 = np.random.normal(intercept_mu_GR5, intercept_sigma_GR5)\n",
    "        B1_GR5   = np.random.normal(B1_mu_GR5, B1_sigma_GR5)\n",
    "        \n",
    "        grmar_5 = intercept_GR5 + B1_GR5 * P_5\n",
    "        \n",
    "        # Profit\n",
    "        revenue_5 = sales_5 * oz_5 * np.exp(P_5)\n",
    "        profits_5 = revenue_5 * grmar_5\n",
    "        \n",
    "        \n",
    "        ####################\n",
    "        #  Appending SKUs  # \n",
    "        ####################\n",
    "        \n",
    "        all_stats.append([sales_1, revenue_1, profits_1, grmar_1,\n",
    "                          sales_2, revenue_2, profits_2, grmar_2,\n",
    "                          sales_3, revenue_3, profits_3, grmar_3,\n",
    "                          sales_4, revenue_4, profits_4, grmar_4,\n",
    "                          sales_5, revenue_5, profits_5, grmar_5])\n",
    "    \n",
    "    results_df = pd.DataFrame.from_records(all_stats,  columns = \n",
    "    ['units_sold_1','revenue_1','profits_1', 'grmar_1',\n",
    "     'units_sold_2','revenue_2','profits_2', 'grmar_2',\n",
    "     'units_sold_3','revenue_3','profits_3', 'grmar_3',\n",
    "     'units_sold_4','revenue_4','profits_4', 'grmar_4',\n",
    "     'units_sold_5','revenue_5','profits_5', 'grmar_5',])\n",
    "        \n",
    "    final_stats.append([np.exp(P_1), np.exp(P_2), np.exp(P_3),\n",
    "                        np.exp(P_4), np.exp(P_5),\n",
    "                        results_df['units_sold_1'].mean(),\n",
    "                        results_df['units_sold_2'].mean(),\n",
    "                        results_df['units_sold_3'].mean(),\n",
    "                        results_df['units_sold_4'].mean(),\n",
    "                        results_df['units_sold_5'].mean(),\n",
    "                        results_df['grmar_1'].mean(),\n",
    "                        results_df['grmar_2'].mean(),\n",
    "                        results_df['grmar_3'].mean(),\n",
    "                        results_df['grmar_4'].mean(),\n",
    "                        results_df['grmar_5'].mean(),\n",
    "                        results_df['profits_1'].mean(),\n",
    "                        results_df['profits_2'].mean(),\n",
    "                        results_df['profits_3'].mean(),\n",
    "                        results_df['profits_4'].mean(),\n",
    "                        results_df['profits_5'].mean(),\n",
    "                        feat1,feat2,feat3,feat4,feat5,\n",
    "                        disp1,disp2,disp3,disp4,disp5])\n",
    "    \n",
    "final_stats_df = pd.DataFrame.from_records(final_stats, columns =\n",
    "                ['Price per Oz_1', 'Price per Oz_2',\n",
    "                 'Price per Oz_3', 'Price per Oz_4', 'Price per Oz_5',\n",
    "                 'Sales_1', 'Sales_2', 'Sales_3', 'Sales_4', 'Sales_5',\n",
    "                 'GrMar_1', 'GrMar_2', 'GrMar_3', 'GrMar_4', 'GrMar_5',\n",
    "                 'Profits_1', 'Profits_2', \n",
    "                 'Profits_3', 'Profits_4', 'Profits_5',\n",
    "                 'Feat_1', 'Feat_2', 'Feat_3', 'Feat_4', 'Feat_5',\n",
    "                 'Disp_1', 'Disp_2', 'Disp_3', 'Disp_4', 'Disp_5'])\n",
    "\n",
    "final_stats_df['Total Profits'] = final_stats_df['Profits_5']\\\n",
    "                                + final_stats_df['Profits_4']\\\n",
    "                                + final_stats_df['Profits_3']\\\n",
    "                                + final_stats_df['Profits_2']\\\n",
    "                                + final_stats_df['Profits_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T01:22:18.002301Z",
     "start_time": "2021-04-01T01:22:16.608Z"
    }
   },
   "outputs": [],
   "source": [
    "df_4_stats = final_stats_df \n",
    "df_4_stats.to_csv('df_4_stats.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T01:22:18.003243Z",
     "start_time": "2021-04-01T01:22:16.610Z"
    }
   },
   "outputs": [],
   "source": [
    "price_msettings_df = df_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T01:22:18.004036Z",
     "start_time": "2021-04-01T01:22:16.612Z"
    }
   },
   "outputs": [],
   "source": [
    "# Monte Carlo Simulation\n",
    "\n",
    "# (Re-) Setting Seed, due to np limitations\n",
    "np.random.seed(42)\n",
    "\n",
    "# Number of simulations per combinations of prices across SKUs'\n",
    "number_sims = 100_000\n",
    "\n",
    "# Store results from each simulation here\n",
    "final_stats = []\n",
    "\n",
    "# Loop over price dataframe\n",
    "for i in tqdm(range(len(price_msettings_df))):\n",
    "    \n",
    "    # Extract price per SKU as log\n",
    "    P_1 = np.log(price_msettings_df.iloc[i, 0])\n",
    "    P_2 = np.log(price_msettings_df.iloc[i, 1])\n",
    "    P_3 = np.log(price_msettings_df.iloc[i, 2])\n",
    "    P_4 = np.log(price_msettings_df.iloc[i, 3])\n",
    "    P_5 = np.log(price_msettings_df.iloc[i, 4])\n",
    "    \n",
    "    # Extract marketing settings per SKU \n",
    "    disp1 = price_msettings_df.iloc[i, 5]\n",
    "    disp2 = price_msettings_df.iloc[i, 6]\n",
    "    disp3 = price_msettings_df.iloc[i, 7]\n",
    "    disp4 = price_msettings_df.iloc[i, 8]\n",
    "    disp5 = price_msettings_df.iloc[i, 9]\n",
    "    \n",
    "    feat1 = price_msettings_df.iloc[i, 10]\n",
    "    feat2 = price_msettings_df.iloc[i, 11]\n",
    "    feat3 = price_msettings_df.iloc[i, 12]\n",
    "    feat4 = price_msettings_df.iloc[i, 13]\n",
    "    feat5 = price_msettings_df.iloc[i, 14]\n",
    "    \n",
    "    # Placeholder\n",
    "    all_stats = []\n",
    "\n",
    "    # Begin Simulation Loop\n",
    "    for i in range(number_sims):\n",
    "        \n",
    "        ###########\n",
    "        #  SKU1   # \n",
    "        ###########\n",
    "        \n",
    "        # Sales\n",
    "        intercept_1 = np.random.normal(intercept_mu_1, intercept_sigma_1)\n",
    "        B1_1   = np.random.normal(B1_mu_P1_1, B1_sigma_P1_1)\n",
    "        B2_1   = np.random.normal(B2_mu_P3_1, B2_sigma_P3_1)\n",
    "        \n",
    "        sales_1 = np.exp(intercept_1 \\\n",
    "                + B1_1 * P_1 \\\n",
    "                + B2_1 * P_3 \\\n",
    "                + B3_mu_D1_1 * disp1 \\\n",
    "                + B4_mu_F1_1 * feat1)\n",
    "        \n",
    "        # Gross Margin\n",
    "        intercept_GR1 = np.random.normal(intercept_mu_GR1, intercept_sigma_GR1)\n",
    "        B1_GR1   = np.random.normal(B1_mu_GR1, B1_sigma_GR1)\n",
    "        \n",
    "        grmar_1 = intercept_GR1 + B1_GR1 * P_1\n",
    "        \n",
    "        # Profit\n",
    "        revenue_1 = sales_1 * oz_1 * np.exp(P_1)\n",
    "        profits_1 = revenue_1 * grmar_1\n",
    "        \n",
    "        \n",
    "        ###########\n",
    "        #  SKU2   # \n",
    "        ###########\n",
    "\n",
    "        # Sales\n",
    "        intercept_2 = np.random.normal(intercept_mu_2, intercept_sigma_2)\n",
    "        B1_2   = np.random.normal(B1_mu_P1_2, B1_sigma_P1_2)\n",
    "        B2_2   = np.random.normal(B2_mu_P2_2, B2_sigma_P2_2)   \n",
    "        \n",
    "        sales_2 = np.exp(intercept_2 \\\n",
    "                + B1_2 * P_1 \\\n",
    "                + B2_2 * P_2 \\\n",
    "                + B3_mu_D2_2 * disp2 \\\n",
    "                + B4_mu_F2_2 * feat2)\n",
    "        \n",
    "        # Gross Margin\n",
    "        intercept_GR2 = np.random.normal(intercept_mu_GR2, intercept_sigma_GR2)\n",
    "        B1_GR2   = np.random.normal(B1_mu_GR2, B1_sigma_GR2)\n",
    "        \n",
    "        grmar_2 = intercept_GR2 + B1_GR2 * P_2\n",
    "        \n",
    "        # Profit\n",
    "        revenue_2 = sales_2 * oz_2 * np.exp(P_2)\n",
    "        profits_2 = revenue_2 * grmar_2\n",
    "        \n",
    "                \n",
    "        ###########\n",
    "        #  SKU3   # \n",
    "        ###########\n",
    "        \n",
    "        # Sales\n",
    "        intercept_3 = np.random.normal(intercept_mu_3, intercept_sigma_3)\n",
    "        B1_3   = np.random.normal(B1_mu_P1_3, B1_sigma_P1_3)\n",
    "        B2_3   = np.random.normal(B2_mu_P3_3, B2_sigma_P3_3)   \n",
    "        B3_3   = np.random.normal(B3_mu_P4_3, B3_sigma_P4_3) \n",
    "\n",
    "        sales_3 = np.exp(intercept_3 \\\n",
    "                + B1_3 * P_1 \\\n",
    "                + B2_3 * P_3 \\\n",
    "                + B3_3 * P_4 \\\n",
    "                + B4_mu_D3_3 * disp3 \\\n",
    "                + B5_mu_F3_3 * feat3)\n",
    "        \n",
    "        # Gross Margin\n",
    "        intercept_GR3 = np.random.normal(intercept_mu_GR3, intercept_sigma_GR3)\n",
    "        B1_GR3   = np.random.normal(B1_mu_GR3, B1_sigma_GR3)\n",
    "        \n",
    "        grmar_3 = intercept_GR3 + B1_GR3 * P_3\n",
    "        \n",
    "        # Profit\n",
    "        revenue_3 = sales_3 * oz_3 * np.exp(P_3)\n",
    "        profits_3 = revenue_3 * grmar_3\n",
    "        \n",
    "        \n",
    "        ###########\n",
    "        #  SKU4   # \n",
    "        ###########\n",
    "        \n",
    "        # Sales\n",
    "        intercept_4 = np.random.normal(intercept_mu_4, intercept_sigma_4)\n",
    "        B1_4   = np.random.normal(B1_mu_P1_4, B1_sigma_P1_4)\n",
    "        B2_4   = np.random.normal(B2_mu_P3_4, B2_sigma_P3_4)   \n",
    "        B3_4   = np.random.normal(B3_mu_P4_4, B3_sigma_P4_4) \n",
    "        B4_4   = np.random.normal(B4_mu_P5_4, B4_sigma_P5_4)\n",
    "        \n",
    "        sales_4 = np.exp(intercept_4 \\\n",
    "                + B1_4 * P_1 \\\n",
    "                + B2_4 * P_3 \\\n",
    "                + B3_4 * P_4 \\\n",
    "                + B4_4 * P_5 \\\n",
    "                + B5_mu_D4_4 * disp4 \\\n",
    "                + B6_mu_F4_4 * feat4)\n",
    "        \n",
    "        # Gross Margin\n",
    "        intercept_GR4 = np.random.normal(intercept_mu_GR4, intercept_sigma_GR4)\n",
    "        B1_GR4   = np.random.normal(B1_mu_GR4, B1_sigma_GR4)\n",
    "        \n",
    "        grmar_4 = intercept_GR4 + B1_GR4 * P_4\n",
    "        \n",
    "        # Profit\n",
    "        revenue_4 = sales_4 * oz_4 * np.exp(P_4)\n",
    "        profits_4 = revenue_4 * grmar_4\n",
    "        \n",
    "        \n",
    "        ###########\n",
    "        #  SKU5   # \n",
    "        ###########\n",
    "        \n",
    "        # Sales\n",
    "        intercept_5 = np.random.normal(intercept_mu_5, intercept_sigma_5)\n",
    "        B1_5   = np.random.normal(B1_mu_P2_5, B1_sigma_P2_5)\n",
    "        B2_5   = np.random.normal(B2_mu_P3_5, B2_sigma_P3_5)   \n",
    "        B3_5   = np.random.normal(B3_mu_P4_5, B3_sigma_P4_5) \n",
    "        B4_5   = np.random.normal(B4_mu_P5_5, B4_sigma_P5_5) \n",
    "        \n",
    "        sales_5 = np.exp(intercept_5 \\\n",
    "                + B1_5 * P_2 \\\n",
    "                + B2_5 * P_3 \\\n",
    "                + B3_5 * P_4 \\\n",
    "                + B4_5 * P_5 \\\n",
    "                + B5_mu_D5_5 * disp5 \\\n",
    "                + B6_mu_F5_5 * feat5)\n",
    "        \n",
    "        # Gross Margin\n",
    "        intercept_GR5 = np.random.normal(intercept_mu_GR5, intercept_sigma_GR5)\n",
    "        B1_GR5   = np.random.normal(B1_mu_GR5, B1_sigma_GR5)\n",
    "        \n",
    "        grmar_5 = intercept_GR5 + B1_GR5 * P_5\n",
    "        \n",
    "        # Profit\n",
    "        revenue_5 = sales_5 * oz_5 * np.exp(P_5)\n",
    "        profits_5 = revenue_5 * grmar_5\n",
    "        \n",
    "        \n",
    "        ####################\n",
    "        #  Appending SKUs  # \n",
    "        ####################\n",
    "        \n",
    "        all_stats.append([sales_1, revenue_1, profits_1, grmar_1,\n",
    "                          sales_2, revenue_2, profits_2, grmar_2,\n",
    "                          sales_3, revenue_3, profits_3, grmar_3,\n",
    "                          sales_4, revenue_4, profits_4, grmar_4,\n",
    "                          sales_5, revenue_5, profits_5, grmar_5])\n",
    "    \n",
    "    results_df = pd.DataFrame.from_records(all_stats,  columns = \n",
    "    ['units_sold_1','revenue_1','profits_1', 'grmar_1',\n",
    "     'units_sold_2','revenue_2','profits_2', 'grmar_2',\n",
    "     'units_sold_3','revenue_3','profits_3', 'grmar_3',\n",
    "     'units_sold_4','revenue_4','profits_4', 'grmar_4',\n",
    "     'units_sold_5','revenue_5','profits_5', 'grmar_5',])\n",
    "        \n",
    "    final_stats.append([np.exp(P_1), np.exp(P_2), np.exp(P_3),\n",
    "                        np.exp(P_4), np.exp(P_5),\n",
    "                        results_df['units_sold_1'].mean(),\n",
    "                        results_df['units_sold_2'].mean(),\n",
    "                        results_df['units_sold_3'].mean(),\n",
    "                        results_df['units_sold_4'].mean(),\n",
    "                        results_df['units_sold_5'].mean(),\n",
    "                        results_df['grmar_1'].mean(),\n",
    "                        results_df['grmar_2'].mean(),\n",
    "                        results_df['grmar_3'].mean(),\n",
    "                        results_df['grmar_4'].mean(),\n",
    "                        results_df['grmar_5'].mean(),\n",
    "                        results_df['profits_1'].mean(),\n",
    "                        results_df['profits_2'].mean(),\n",
    "                        results_df['profits_3'].mean(),\n",
    "                        results_df['profits_4'].mean(),\n",
    "                        results_df['profits_5'].mean(),\n",
    "                        feat1,feat2,feat3,feat4,feat5,\n",
    "                        disp1,disp2,disp3,disp4,disp5])\n",
    "    \n",
    "final_stats_df = pd.DataFrame.from_records(final_stats, columns =\n",
    "                ['Price per Oz_1', 'Price per Oz_2',\n",
    "                 'Price per Oz_3', 'Price per Oz_4', 'Price per Oz_5',\n",
    "                 'Sales_1', 'Sales_2', 'Sales_3', 'Sales_4', 'Sales_5',\n",
    "                 'GrMar_1', 'GrMar_2', 'GrMar_3', 'GrMar_4', 'GrMar_5',\n",
    "                 'Profits_1', 'Profits_2', \n",
    "                 'Profits_3', 'Profits_4', 'Profits_5',\n",
    "                 'Feat_1', 'Feat_2', 'Feat_3', 'Feat_4', 'Feat_5',\n",
    "                 'Disp_1', 'Disp_2', 'Disp_3', 'Disp_4', 'Disp_5'])\n",
    "\n",
    "final_stats_df['Total Profits'] = final_stats_df['Profits_5']\\\n",
    "                                + final_stats_df['Profits_4']\\\n",
    "                                + final_stats_df['Profits_3']\\\n",
    "                                + final_stats_df['Profits_2']\\\n",
    "                                + final_stats_df['Profits_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T01:22:18.004686Z",
     "start_time": "2021-04-01T01:22:16.614Z"
    }
   },
   "outputs": [],
   "source": [
    "df_5_stats = final_stats_df \n",
    "df_5_stats.to_csv('df_5_stats.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T01:22:18.005414Z",
     "start_time": "2021-04-01T01:22:16.615Z"
    }
   },
   "outputs": [],
   "source": [
    "r1 = pd.read_csv('df_1_stats.csv')\n",
    "r2 = pd.read_csv('df_2_stats.csv')\n",
    "r3 = pd.read_csv('df_3_stats.csv')\n",
    "r4 = pd.read_csv('df_4_stats.csv')\n",
    "r5 = pd.read_csv('df_5_stats.csv')\n",
    "\n",
    "df_2500_top = pd.concat([r1,r2,r3,r4,r5])\n",
    "df_2500_top.to_csv('results_2500_top.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
