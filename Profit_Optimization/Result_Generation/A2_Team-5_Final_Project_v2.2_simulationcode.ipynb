{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "contrary-sample",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-26T00:01:18.103553Z",
     "start_time": "2021-03-26T00:01:18.096395Z"
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<br><br><br><br><br>\n",
    "<u><b><font size = 6>A2: Team Project OJ </f></b></u><br><br>\n",
    "<b><font size = 5> Data Optimization - DAT-5304 </f></b>\n",
    "<br><br>\n",
    "<b>Authors</b>          : Carolina Novello Moreira, Jack Daoud & Max Lembke <br>\n",
    "<b>Date Created</b> : 03/24/2021<br>\n",
    "<br><br><br><br><br>\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flying-michael",
   "metadata": {},
   "source": [
    "# Set-up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dental-billy",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T02:39:36.156762Z",
     "start_time": "2021-03-31T02:39:36.090937Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import packages \n",
    "import pandas as pd #pandas \n",
    "import numpy  as np #numpy \n",
    "from numpy import arange # for ranges with floats\n",
    "import statsmodels.formula.api as smf # predictive modeling with nice outputs\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas import DataFrame\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Set options \n",
    "pd.set_option(\"display.max_rows\", 999)\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "\n",
    "# Importing file \n",
    "df = pd.read_excel('OJ_Data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "extensive-pantyhose",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T02:39:36.163744Z",
     "start_time": "2021-03-31T02:39:36.157760Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Helper functions \n",
    "\n",
    "# Make binary function \n",
    "def make_binary(df):\n",
    "    \n",
    "    for col in df.columns:\n",
    "        \n",
    "        if 'feat' in col \\\n",
    "        or 'disp' in col:\n",
    "            \n",
    "            for index, value in df.iterrows():\n",
    "                \n",
    "                if df.loc[index, col] >= 0.5:\n",
    "                    df.loc[index, col] = 1\n",
    "                else:\n",
    "                    df.loc[index, col] = 0\n",
    "        \n",
    "            df[col] = df[col].astype(int)\n",
    "\n",
    "\n",
    "# Shuffle dataframe function\n",
    "def shuffle(df, n = 1, axis = 0):     \n",
    "    df = df.copy()\n",
    "    for _ in range(n):\n",
    "        df.apply(np.random.shuffle, axis = axis)\n",
    "        return df\n",
    "\n",
    "# Source:\n",
    "# https://stackoverflow.com/questions/15772009/shuffling-permutating-a-dataframe-in-pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "above-yahoo",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T02:39:36.514834Z",
     "start_time": "2021-03-31T02:39:36.165737Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data cleaning \n",
    "\n",
    "# Clean binary variables\n",
    "make_binary(df)\n",
    "\n",
    "\n",
    "# Log transformations \n",
    "\n",
    "# Price\n",
    "df['log_price1'] = np.log(df['price1'])\n",
    "df['log_price2'] = np.log(df['price2'])\n",
    "df['log_price3'] = np.log(df['price3'])\n",
    "df['log_price4'] = np.log(df['price4'])\n",
    "df['log_price5'] = np.log(df['price5'])\n",
    "\n",
    "# Sales\n",
    "df['log_sales1'] = np.log(df['sales1'])\n",
    "df['log_sales2'] = np.log(df['sales2'])\n",
    "df['log_sales3'] = np.log(df['sales3'])\n",
    "df['log_sales4'] = np.log(df['sales4'])\n",
    "df['log_sales5'] = np.log(df['sales5'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solid-cabinet",
   "metadata": {},
   "source": [
    "# Part 1: Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimum-nutrition",
   "metadata": {},
   "source": [
    "## Product 1: Tropicana Premium 64 oz\n",
    "\n",
    "### Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "surprised-pride",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T02:39:36.519822Z",
     "start_time": "2021-03-31T02:39:36.515833Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # step 1: build a model\n",
    "# lm_best = smf.ols(formula =  \"\"\"log_sales1 ~ log_price1 +\n",
    "#                                         log_price2 +\n",
    "#                                         log_price3 +\n",
    "#                                         log_price4 +\n",
    "#                                         log_price5 +\n",
    "#                                         disp1 +\n",
    "#                                         feat1\"\"\",\n",
    "#                                         data = df)\n",
    "\n",
    "\n",
    "# # step 2: fit the model based on the data\n",
    "# results_1 = lm_best.fit()\n",
    "\n",
    "# # step 3: analyze the summary output\n",
    "# print(results_1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "supported-precipitation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T02:39:36.544754Z",
     "start_time": "2021-03-31T02:39:36.520819Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             log_sales1   R-squared:                       0.793\n",
      "Model:                            OLS   Adj. R-squared:                  0.786\n",
      "Method:                 Least Squares   F-statistic:                     106.5\n",
      "Date:                Tue, 30 Mar 2021   Prob (F-statistic):           4.46e-37\n",
      "Time:                        22:39:36   Log-Likelihood:                -39.767\n",
      "No. Observations:                 116   AIC:                             89.53\n",
      "Df Residuals:                     111   BIC:                             103.3\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      3.0708      0.817      3.759      0.000       1.452       4.690\n",
      "log_price1    -2.6331      0.213    -12.379      0.000      -3.055      -2.212\n",
      "log_price3     0.5614      0.179      3.140      0.002       0.207       0.916\n",
      "disp1         -0.0199      0.088     -0.227      0.821      -0.193       0.154\n",
      "feat1          0.6419      0.095      6.759      0.000       0.454       0.830\n",
      "==============================================================================\n",
      "Omnibus:                        5.505   Durbin-Watson:                   1.715\n",
      "Prob(Omnibus):                  0.064   Jarque-Bera (JB):                8.276\n",
      "Skew:                          -0.053   Prob(JB):                       0.0160\n",
      "Kurtosis:                       4.304   Cond. No.                         122.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Re-running the the regression without variables with p-values above 0.05\n",
    "\n",
    "# step 1: build a model\n",
    "lm_best = smf.ols(formula =  \"\"\"log_sales1 ~ log_price1 +\n",
    "                                        log_price3 +\n",
    "                                        disp1 +\n",
    "                                        feat1\"\"\",\n",
    "                                        data = df)\n",
    "\n",
    "\n",
    "# step 2: fit the model based on the data\n",
    "results_1_opt = lm_best.fit()\n",
    "\n",
    "# step 3: analyze the summary output\n",
    "print(results_1_opt.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "buried-cedar",
   "metadata": {},
   "source": [
    "### Gross Margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "universal-ceiling",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T02:39:36.570686Z",
     "start_time": "2021-03-31T02:39:36.545751Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 grmar1   R-squared:                       0.585\n",
      "Model:                            OLS   Adj. R-squared:                  0.582\n",
      "Method:                 Least Squares   F-statistic:                     161.0\n",
      "Date:                Tue, 30 Mar 2021   Prob (F-statistic):           1.55e-23\n",
      "Time:                        22:39:36   Log-Likelihood:                 130.37\n",
      "No. Observations:                 116   AIC:                            -256.7\n",
      "Df Residuals:                     114   BIC:                            -251.2\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      1.6923      0.112     15.162      0.000       1.471       1.913\n",
      "log_price1     0.4537      0.036     12.687      0.000       0.383       0.525\n",
      "==============================================================================\n",
      "Omnibus:                       14.775   Durbin-Watson:                   0.530\n",
      "Prob(Omnibus):                  0.001   Jarque-Bera (JB):                4.631\n",
      "Skew:                           0.080   Prob(JB):                       0.0987\n",
      "Kurtosis:                       2.034   Cond. No.                         52.1\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# step 1: build a model\n",
    "lm_best = smf.ols(formula =  \"\"\"grmar1 ~ log_price1\"\"\",\n",
    "                                        data = df)\n",
    "\n",
    "\n",
    "# step 2: fit the model based on the data\n",
    "results_grmar_1 = lm_best.fit()\n",
    "\n",
    "# step 3: analyze the summary output\n",
    "print(results_grmar_1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dated-fiber",
   "metadata": {},
   "source": [
    "## Product 2: Tropicana Premium 96 oz\n",
    "\n",
    "### Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "mobile-madness",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T02:39:36.582657Z",
     "start_time": "2021-03-31T02:39:36.572680Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # step 1: build a model\n",
    "# lm_best = smf.ols(formula =  \"\"\"log_sales2 ~ log_price1 +\n",
    "#                                         log_price2 +\n",
    "#                                         log_price3 +\n",
    "#                                         log_price4 +\n",
    "#                                         log_price5 +\n",
    "#                                         disp2 +\n",
    "#                                         feat2\"\"\",\n",
    "#                                         data = df)\n",
    "\n",
    "\n",
    "# # step 2: fit the model based on the data\n",
    "# results_2 = lm_best.fit()\n",
    "\n",
    "# # step 3: analyze the summary output\n",
    "# print(results_2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "chief-calvin",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T02:39:36.622546Z",
     "start_time": "2021-03-31T02:39:36.586643Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             log_sales2   R-squared:                       0.552\n",
      "Model:                            OLS   Adj. R-squared:                  0.536\n",
      "Method:                 Least Squares   F-statistic:                     34.20\n",
      "Date:                Tue, 30 Mar 2021   Prob (F-statistic):           1.39e-18\n",
      "Time:                        22:39:36   Log-Likelihood:                 10.491\n",
      "No. Observations:                 116   AIC:                            -10.98\n",
      "Df Residuals:                     111   BIC:                             2.786\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      5.4557      0.631      8.643      0.000       4.205       6.706\n",
      "log_price1     0.3164      0.110      2.884      0.005       0.099       0.534\n",
      "log_price2    -1.5982      0.225     -7.106      0.000      -2.044      -1.153\n",
      "disp2          0.0305      0.057      0.539      0.591      -0.082       0.143\n",
      "feat2          0.3048      0.070      4.331      0.000       0.165       0.444\n",
      "==============================================================================\n",
      "Omnibus:                        1.401   Durbin-Watson:                   1.260\n",
      "Prob(Omnibus):                  0.496   Jarque-Bera (JB):                0.916\n",
      "Skew:                           0.106   Prob(JB):                        0.633\n",
      "Kurtosis:                       3.380   Cond. No.                         140.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Re-running the the regression without variables with p-values above 0.05\n",
    "\n",
    "# step 1: build a model\n",
    "lm_best = smf.ols(formula =  \"\"\"log_sales2 ~ log_price1 +\n",
    "                                        log_price2 +\n",
    "                                        disp2 +\n",
    "                                        feat2\"\"\",\n",
    "                                        data = df)\n",
    "\n",
    "\n",
    "# step 2: fit the model based on the data\n",
    "results_2_opt = lm_best.fit()\n",
    "\n",
    "# step 3: analyze the summary output\n",
    "print(results_2_opt.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incredible-barrel",
   "metadata": {},
   "source": [
    "### Gross Margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "strong-jewelry",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T02:39:36.650473Z",
     "start_time": "2021-03-31T02:39:36.625540Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 grmar2   R-squared:                       0.504\n",
      "Model:                            OLS   Adj. R-squared:                  0.500\n",
      "Method:                 Least Squares   F-statistic:                     116.0\n",
      "Date:                Tue, 30 Mar 2021   Prob (F-statistic):           4.40e-19\n",
      "Time:                        22:39:36   Log-Likelihood:                 197.88\n",
      "No. Observations:                 116   AIC:                            -391.8\n",
      "Df Residuals:                     114   BIC:                            -386.3\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      1.4363      0.107     13.433      0.000       1.224       1.648\n",
      "log_price2     0.3834      0.036     10.770      0.000       0.313       0.454\n",
      "==============================================================================\n",
      "Omnibus:                        1.543   Durbin-Watson:                   1.053\n",
      "Prob(Omnibus):                  0.462   Jarque-Bera (JB):                1.440\n",
      "Skew:                          -0.270   Prob(JB):                        0.487\n",
      "Kurtosis:                       2.923   Cond. No.                         86.7\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# step 1: build a model\n",
    "lm_best = smf.ols(formula =  \"\"\"grmar2 ~ log_price2\"\"\",\n",
    "                                        data = df)\n",
    "\n",
    "\n",
    "# step 2: fit the model based on the data\n",
    "results_grmar_2 = lm_best.fit()\n",
    "\n",
    "# step 3: analyze the summary output\n",
    "print(results_grmar_2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neutral-remark",
   "metadata": {},
   "source": [
    "## Product 3: Topicana 64 oz\n",
    "\n",
    "### Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "scheduled-reputation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T02:39:36.668426Z",
     "start_time": "2021-03-31T02:39:36.652468Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # step 1: build a model\n",
    "# lm_best = smf.ols(formula =  \"\"\"log_sales3 ~ log_price1 +\n",
    "#                                         log_price2 +\n",
    "#                                         log_price3 +\n",
    "#                                         log_price4 +\n",
    "#                                         log_price5 +\n",
    "#                                         disp3 +\n",
    "#                                         feat3\"\"\",\n",
    "#                                         data = df)\n",
    "\n",
    "\n",
    "# # step 2: fit the model based on the data\n",
    "# results_3 = lm_best.fit()\n",
    "\n",
    "# # step 3: analyze the summary output\n",
    "# print(results_3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "living-evans",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T02:39:36.711310Z",
     "start_time": "2021-03-31T02:39:36.670419Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             log_sales3   R-squared:                       0.705\n",
      "Model:                            OLS   Adj. R-squared:                  0.691\n",
      "Method:                 Least Squares   F-statistic:                     52.46\n",
      "Date:                Tue, 30 Mar 2021   Prob (F-statistic):           1.43e-27\n",
      "Time:                        22:39:36   Log-Likelihood:                -128.44\n",
      "No. Observations:                 116   AIC:                             268.9\n",
      "Df Residuals:                     110   BIC:                             285.4\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      3.0170      2.029      1.487      0.140      -1.004       7.038\n",
      "log_price1     1.3084      0.354      3.694      0.000       0.606       2.010\n",
      "log_price3    -4.3149      0.471     -9.155      0.000      -5.249      -3.381\n",
      "log_price4     1.5322      0.455      3.367      0.001       0.630       2.434\n",
      "disp3          0.1899      0.171      1.110      0.269      -0.149       0.529\n",
      "feat3          1.0187      0.169      6.036      0.000       0.684       1.353\n",
      "==============================================================================\n",
      "Omnibus:                        8.785   Durbin-Watson:                   1.581\n",
      "Prob(Omnibus):                  0.012   Jarque-Bera (JB):                9.531\n",
      "Skew:                           0.499   Prob(JB):                      0.00852\n",
      "Kurtosis:                       3.988   Cond. No.                         171.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Re-running the the regression without variables with p-values above 0.05\n",
    "\n",
    "# step 1: build a model\n",
    "lm_best = smf.ols(formula =  \"\"\"log_sales3 ~ log_price1 +\n",
    "                                        log_price3 +\n",
    "                                        log_price4 +\n",
    "                                        disp3 +\n",
    "                                        feat3\"\"\",\n",
    "                                        data = df)\n",
    "\n",
    "\n",
    "# step 2: fit the model based on the data\n",
    "results_3_opt = lm_best.fit()\n",
    "\n",
    "# step 3: analyze the summary output\n",
    "print(results_3_opt.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "induced-confusion",
   "metadata": {},
   "source": [
    "### Gross Margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ignored-fifty",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T02:39:36.735246Z",
     "start_time": "2021-03-31T02:39:36.713304Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 grmar3   R-squared:                       0.534\n",
      "Model:                            OLS   Adj. R-squared:                  0.530\n",
      "Method:                 Least Squares   F-statistic:                     130.5\n",
      "Date:                Tue, 30 Mar 2021   Prob (F-statistic):           1.30e-20\n",
      "Time:                        22:39:36   Log-Likelihood:                 132.17\n",
      "No. Observations:                 116   AIC:                            -260.3\n",
      "Df Residuals:                     114   BIC:                            -254.8\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      1.8110      0.133     13.624      0.000       1.548       2.074\n",
      "log_price3     0.4539      0.040     11.425      0.000       0.375       0.533\n",
      "==============================================================================\n",
      "Omnibus:                        7.207   Durbin-Watson:                   0.605\n",
      "Prob(Omnibus):                  0.027   Jarque-Bera (JB):                7.343\n",
      "Skew:                          -0.616   Prob(JB):                       0.0254\n",
      "Kurtosis:                       2.973   Cond. No.                         66.8\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# step 1: build a model\n",
    "lm_best = smf.ols(formula =  \"\"\"grmar3 ~ log_price3\"\"\",\n",
    "                                        data = df)\n",
    "\n",
    "\n",
    "# step 2: fit the model based on the data\n",
    "results_grmar_3 = lm_best.fit()\n",
    "\n",
    "# step 3: analyze the summary output\n",
    "print(results_grmar_3.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valued-grade",
   "metadata": {},
   "source": [
    "## Product 4: Minute Maid 64 oz\n",
    "\n",
    "### Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "painful-effectiveness",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T02:39:36.741229Z",
     "start_time": "2021-03-31T02:39:36.737240Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # step 1: build a model\n",
    "# lm_best = smf.ols(formula =  \"\"\"log_sales4 ~ log_price1 +\n",
    "#                                         log_price2 +\n",
    "#                                         log_price3 +\n",
    "#                                         log_price4 +\n",
    "#                                         log_price5 +\n",
    "#                                         disp4 +\n",
    "#                                         feat4\"\"\",\n",
    "#                                         data = df)\n",
    "\n",
    "\n",
    "# # step 2: fit the model based on the data\n",
    "# results_4 = lm_best.fit()\n",
    "\n",
    "# # step 3: analyze the summary output\n",
    "# print(results_4.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "motivated-mention",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T02:39:36.778130Z",
     "start_time": "2021-03-31T02:39:36.743225Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             log_sales4   R-squared:                       0.751\n",
      "Model:                            OLS   Adj. R-squared:                  0.737\n",
      "Method:                 Least Squares   F-statistic:                     54.78\n",
      "Date:                Tue, 30 Mar 2021   Prob (F-statistic):           1.12e-30\n",
      "Time:                        22:39:36   Log-Likelihood:                -74.809\n",
      "No. Observations:                 116   AIC:                             163.6\n",
      "Df Residuals:                     109   BIC:                             182.9\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      5.9598      1.488      4.005      0.000       3.011       8.909\n",
      "log_price1     0.5653      0.238      2.376      0.019       0.094       1.037\n",
      "log_price3     0.6214      0.259      2.397      0.018       0.108       1.135\n",
      "log_price4    -2.6623      0.382     -6.976      0.000      -3.419      -1.906\n",
      "log_price5     0.5762      0.207      2.783      0.006       0.166       0.987\n",
      "disp4          0.1964      0.132      1.492      0.138      -0.064       0.457\n",
      "feat4          0.8731      0.130      6.724      0.000       0.616       1.131\n",
      "==============================================================================\n",
      "Omnibus:                       29.629   Durbin-Watson:                   1.828\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               63.769\n",
      "Skew:                           1.013   Prob(JB):                     1.42e-14\n",
      "Kurtosis:                       6.015   Cond. No.                         234.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Re-running the the regression without variables with p-values above 0.05\n",
    "\n",
    "# step 1: build a model\n",
    "lm_best = smf.ols(formula =  \"\"\"log_sales4 ~ log_price1 +\n",
    "                                        log_price3 +\n",
    "                                        log_price4 +\n",
    "                                        log_price5 +\n",
    "                                        disp4 +\n",
    "                                        feat4\"\"\",\n",
    "                                        data = df)\n",
    "\n",
    "\n",
    "# step 2: fit the model based on the data\n",
    "results_4_opt = lm_best.fit()\n",
    "\n",
    "# step 3: analyze the summary output\n",
    "print(results_4_opt.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "listed-anatomy",
   "metadata": {},
   "source": [
    "### Gross Margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "greatest-tongue",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T02:39:36.806056Z",
     "start_time": "2021-03-31T02:39:36.779128Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 grmar4   R-squared:                       0.486\n",
      "Model:                            OLS   Adj. R-squared:                  0.482\n",
      "Method:                 Least Squares   F-statistic:                     108.0\n",
      "Date:                Tue, 30 Mar 2021   Prob (F-statistic):           3.39e-18\n",
      "Time:                        22:39:36   Log-Likelihood:                 130.48\n",
      "No. Observations:                 116   AIC:                            -257.0\n",
      "Df Residuals:                     114   BIC:                            -251.5\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      1.7289      0.142     12.159      0.000       1.447       2.011\n",
      "log_price4     0.4398      0.042     10.391      0.000       0.356       0.524\n",
      "==============================================================================\n",
      "Omnibus:                        0.240   Durbin-Watson:                   0.721\n",
      "Prob(Omnibus):                  0.887   Jarque-Bera (JB):                0.325\n",
      "Skew:                          -0.104   Prob(JB):                        0.850\n",
      "Kurtosis:                       2.845   Cond. No.                         70.7\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# step 1: build a model\n",
    "lm_best = smf.ols(formula =  \"\"\"grmar4 ~ log_price4\"\"\",\n",
    "                                        data = df)\n",
    "\n",
    "\n",
    "# step 2: fit the model based on the data\n",
    "results_grmar_4 = lm_best.fit()\n",
    "\n",
    "# step 3: analyze the summary output\n",
    "print(results_grmar_4.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpha-bulgaria",
   "metadata": {},
   "source": [
    "## Product 5: Dominick's 64 oz\n",
    "\n",
    "### Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "liable-consent",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T02:39:36.815032Z",
     "start_time": "2021-03-31T02:39:36.808051Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # step 1: build a model\n",
    "# lm_best = smf.ols(formula =  \"\"\"log_sales5 ~ log_price1 +\n",
    "#                                         log_price2 +\n",
    "#                                         log_price3 +\n",
    "#                                         log_price4 +\n",
    "#                                         log_price5 +\n",
    "#                                         disp5 +\n",
    "#                                         feat5\"\"\",\n",
    "#                                         data = df)\n",
    "\n",
    "\n",
    "# # step 2: fit the model based on the data\n",
    "# results_5 = lm_best.fit()\n",
    "\n",
    "# # step 3: analyze the summary output\n",
    "# print(results_5.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "structured-contamination",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T02:39:36.857918Z",
     "start_time": "2021-03-31T02:39:36.817027Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             log_sales5   R-squared:                       0.667\n",
      "Model:                            OLS   Adj. R-squared:                  0.649\n",
      "Method:                 Least Squares   F-statistic:                     36.39\n",
      "Date:                Tue, 30 Mar 2021   Prob (F-statistic):           6.66e-24\n",
      "Time:                        22:39:36   Log-Likelihood:                -118.19\n",
      "No. Observations:                 116   AIC:                             250.4\n",
      "Df Residuals:                     109   BIC:                             269.7\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -0.6726      2.141     -0.314      0.754      -4.915       3.570\n",
      "log_price2    -1.6261      0.595     -2.733      0.007      -2.806      -0.447\n",
      "log_price3     1.0544      0.364      2.900      0.005       0.334       1.775\n",
      "log_price4     1.1239      0.389      2.893      0.005       0.354       1.894\n",
      "log_price5    -3.2319      0.349     -9.272      0.000      -3.923      -2.541\n",
      "disp5          0.2854      0.143      1.999      0.048       0.002       0.568\n",
      "feat5          0.6610      0.154      4.291      0.000       0.356       0.966\n",
      "==============================================================================\n",
      "Omnibus:                        4.516   Durbin-Watson:                   1.680\n",
      "Prob(Omnibus):                  0.105   Jarque-Bera (JB):                4.471\n",
      "Skew:                          -0.274   Prob(JB):                        0.107\n",
      "Kurtosis:                       3.790   Cond. No.                         230.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Re-running the the regression without variables with p-values above 0.05\n",
    "\n",
    "# step 1: build a model\n",
    "lm_best_opt = smf.ols(formula =  \"\"\"log_sales5 ~ log_price2 +\n",
    "                                        log_price3 +\n",
    "                                        log_price4 +\n",
    "                                        log_price5 +\n",
    "                                        disp5 +\n",
    "                                        feat5\"\"\",\n",
    "                                        data = df)\n",
    "\n",
    "\n",
    "# step 2: fit the model based on the data\n",
    "results_5_opt = lm_best_opt.fit()\n",
    "\n",
    "# step 3: analyze the summary output\n",
    "print(results_5_opt.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ideal-cambodia",
   "metadata": {},
   "source": [
    "### Gross Margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fleet-vertex",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T02:39:36.881854Z",
     "start_time": "2021-03-31T02:39:36.859912Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 grmar5   R-squared:                       0.527\n",
      "Model:                            OLS   Adj. R-squared:                  0.522\n",
      "Method:                 Least Squares   F-statistic:                     126.8\n",
      "Date:                Tue, 30 Mar 2021   Prob (F-statistic):           3.16e-20\n",
      "Time:                        22:39:36   Log-Likelihood:                 105.93\n",
      "No. Observations:                 116   AIC:                            -207.9\n",
      "Df Residuals:                     114   BIC:                            -202.4\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      2.0035      0.152     13.164      0.000       1.702       2.305\n",
      "log_price5     0.4695      0.042     11.260      0.000       0.387       0.552\n",
      "==============================================================================\n",
      "Omnibus:                        2.499   Durbin-Watson:                   0.750\n",
      "Prob(Omnibus):                  0.287   Jarque-Bera (JB):                2.330\n",
      "Skew:                           0.020   Prob(JB):                        0.312\n",
      "Kurtosis:                       3.693   Cond. No.                         65.7\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# step 1: build a model\n",
    "lm_best = smf.ols(formula =  \"\"\"grmar5 ~ log_price5\"\"\",\n",
    "                                        data = df)\n",
    "\n",
    "\n",
    "# step 2: fit the model based on the data\n",
    "results_grmar_5 = lm_best.fit()\n",
    "\n",
    "# step 3: analyze the summary output\n",
    "print(results_grmar_5.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inappropriate-worst",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "# Part 2: Monte Carlo\n",
    "\n",
    "## Constant Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "excited-annual",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T02:39:36.951667Z",
     "start_time": "2021-03-31T02:39:36.883848Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Setup constant variables\n",
    "\n",
    "# (Re-) Setting Seed, due to np limitations\n",
    "np.random.seed(42)  \n",
    "\n",
    "# Devisor for sigma \n",
    "\n",
    "d_sigma = 2 \n",
    "\n",
    "# Ounces per SKU\n",
    "oz_1 = 64\n",
    "oz_2 = 96\n",
    "oz_3 = 64\n",
    "oz_4 = 64\n",
    "oz_5 = 64\n",
    "\n",
    "############################\n",
    "# Historical Data Overview #\n",
    "############################\n",
    "\n",
    "# Average price per SKU\n",
    "price1_avg = round((df['price1'].mean() * oz_1),2)\n",
    "price2_avg = round((df['price2'].mean() * oz_2),2)\n",
    "price3_avg = round((df['price3'].mean() * oz_2),2)\n",
    "price4_avg = round((df['price4'].mean() * oz_4),2)\n",
    "price5_avg = round((df['price5'].mean() * oz_5),2)\n",
    "\n",
    "# Units sold per SKU\n",
    "units_sold_1 = round(df['sales1'].mean(),2)\n",
    "units_sold_2 = round(df['sales2'].mean(),2)\n",
    "units_sold_3 = round(df['sales3'].mean(),2)\n",
    "units_sold_4 = round(df['sales4'].mean(),2)\n",
    "units_sold_5 = round(df['sales5'].mean(),2)\n",
    "\n",
    "# Average gross margin per SKU\n",
    "grmar1_avg = round(df['grmar1'].mean()*100,2)\n",
    "grmar2_avg = round(df['grmar2'].mean()*100,2)\n",
    "grmar3_avg = round(df['grmar3'].mean()*100,2)\n",
    "grmar4_avg = round(df['grmar4'].mean()*100,2)\n",
    "grmar5_avg = round(df['grmar5'].mean()*100,2)\n",
    "\n",
    "# Revenue per SKU \n",
    "revenue_1 = df['sales1'] * oz_1 * df['price1']\n",
    "avg_revenue_1 = round(revenue_1.mean(),2)\n",
    "\n",
    "revenue_2 = df['sales2'] * oz_2 * df['price2']\n",
    "avg_revenue_2 = round(revenue_2.mean(),2)\n",
    "\n",
    "revenue_3 = df['sales3'] * oz_3 * df['price3']\n",
    "avg_revenue_3 = round(revenue_3.mean(),2)\n",
    "\n",
    "revenue_4 = df['sales4'] * oz_4 * df['price4']\n",
    "avg_revenue_4 = round(revenue_4.mean(),2)\n",
    "\n",
    "revenue_5 = df['sales5'] * oz_5 * df['price5']\n",
    "avg_revenue_5 = round(revenue_5.mean(),2)\n",
    "\n",
    "\n",
    "# Profits per SKU\n",
    "profits_1 = revenue_1 * df['grmar1']\n",
    "avg_profits_1 = round(profits_1.mean(),2)\n",
    "\n",
    "profits_2 = revenue_2 * df['grmar2']\n",
    "avg_profits_2 = round(profits_2.mean(),2)\n",
    "\n",
    "profits_3 = revenue_3 * df['grmar3']\n",
    "avg_profits_3 = round(profits_3.mean(),2)\n",
    "\n",
    "profits_4 = revenue_4 * df['grmar4']\n",
    "avg_profits_4 = round(profits_4.mean(),2)\n",
    "\n",
    "profits_5 = revenue_5 * df['grmar5']\n",
    "avg_profits_5 = round(profits_5.mean(),2)\n",
    "\n",
    "total_profits = profits_1 + profits_2 + profits_3 + profits_4 + profits_5\n",
    "avg_total_profits = round(total_profits.mean(),2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##################\n",
    "#  Gross Margin  #\n",
    "##############################################################################\n",
    "# Set up random draw parameters for coefficients - SKU1 (GRMAR)\n",
    "\n",
    "# intercept \n",
    "intercept_mu_GR1    = results_grmar_1.params[0]  # coefficient from regression\n",
    "intercept_sigma_GR1 = results_grmar_1.bse[0]     # standard error from regression\n",
    "\n",
    "# gross margin\n",
    "B1_mu_GR1    = results_grmar_1.params[1]\n",
    "B1_sigma_GR1 = results_grmar_1.bse[1]\n",
    "\n",
    "##############################################################################\n",
    "# Set up random draw parameters for coefficients - SKU2 (GRMAR)\n",
    "\n",
    "# intercept \n",
    "intercept_mu_GR2    = results_grmar_2.params[0]  # coefficient from regression\n",
    "intercept_sigma_GR2 = results_grmar_2.bse[0]    # standard error from regression\n",
    "\n",
    "# gross margin\n",
    "B1_mu_GR2    = results_grmar_2.params[1]\n",
    "B1_sigma_GR2 = results_grmar_2.bse[1]\n",
    "\n",
    "##############################################################################\n",
    "# Set up random draw parameters for coefficients - SKU3 (GRMAR)\n",
    "\n",
    "# intercept \n",
    "intercept_mu_GR3    = results_grmar_3.params[0]  # coefficient from regression\n",
    "intercept_sigma_GR3 = results_grmar_3.bse[0]     # standard error from regression\n",
    "\n",
    "# gross margin\n",
    "B1_mu_GR3    = results_grmar_3.params[1]\n",
    "B1_sigma_GR3 = results_grmar_3.bse[1]\n",
    "\n",
    "##############################################################################\n",
    "# Set up random draw parameters for coefficients - SKU4 (GRMAR)\n",
    "\n",
    "# intercept \n",
    "intercept_mu_GR4    = results_grmar_4.params[0]  # coefficient from regression\n",
    "intercept_sigma_GR4 = results_grmar_4.bse[0]     # standard error from regression\n",
    "\n",
    "# gross margin\n",
    "B1_mu_GR4    = results_grmar_4.params[1]\n",
    "B1_sigma_GR4 = results_grmar_4.bse[1]\n",
    "\n",
    "##############################################################################\n",
    "# Set up random draw parameters for coefficients - SKU5 (GRMAR)\n",
    "\n",
    "# intercept \n",
    "intercept_mu_GR5    = results_grmar_5.params[0]  # coefficient from regression\n",
    "intercept_sigma_GR5 = results_grmar_5.bse[0]     # standard error from regression\n",
    "\n",
    "# gross margin\n",
    "B1_mu_GR5    = results_grmar_5.params[1]\n",
    "B1_sigma_GR5 = results_grmar_5.bse[1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###########\n",
    "#  Sales  #\n",
    "##############################################################################\n",
    "# Set up random draw parameters for coefficients - SKU1 (Sales)\n",
    "\n",
    "# intercept \n",
    "intercept_mu_1    = results_1_opt.params[0]          # coefficient from regression\n",
    "intercept_sigma_1 = results_1_opt.bse[0]/d_sigma     # standard error from regression\n",
    "\n",
    "# price SKU1\n",
    "B1_mu_P1_1    = results_1_opt.params[1]              # coefficient from regression\n",
    "B1_sigma_P1_1 = results_1_opt.bse[1]/d_sigma         # standard error from regression\n",
    "\n",
    "# price SKU3\n",
    "B2_mu_P3_1    = results_1_opt.params[2]              # coefficient from regression\n",
    "B2_sigma_P3_1 = results_1_opt.bse[2]/d_sigma         # standard error from regression\n",
    "\n",
    "# disp1 SKU1\n",
    "B3_mu_D1_1 = results_1_opt.params[3]                 # coefficient from regression\n",
    "\n",
    "# feat1 SKU1\n",
    "B4_mu_F1_1 = results_1_opt.params[4]                 # coefficient from regression\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# Set up random draw parameters for coefficients - SKU2 (Sales)\n",
    "\n",
    "# intercept \n",
    "intercept_mu_2    = results_2_opt.params[0]         # coefficient from regression\n",
    "intercept_sigma_2 = results_2_opt.bse[0]/d_sigma    # standard error from regression\n",
    "\n",
    "# price SKU1\n",
    "B1_mu_P1_2    = results_2_opt.params[1]             # coefficient from regression\n",
    "B1_sigma_P1_2 = results_2_opt.bse[1]/d_sigma        # standard error from regression\n",
    "\n",
    "# price SKU2\n",
    "B2_mu_P2_2    = results_2_opt.params[2]             # coefficient from regression\n",
    "B2_sigma_P2_2 = results_2_opt.bse[2]/d_sigma        # standard error from regression\n",
    "\n",
    "# disp2 SKU2\n",
    "B3_mu_D2_2 = results_2_opt.params[3]                # coefficient from regression\n",
    "\n",
    "# feat2 SKU2\n",
    "B4_mu_F2_2 = results_2_opt.params[4]                # coefficient from regression\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# Set up random draw parameters for coefficients - SKU3 (Sales)\n",
    "\n",
    "# intercept \n",
    "intercept_mu_3    = results_3_opt.params[0]          # coefficient from regression\n",
    "intercept_sigma_3 = results_3_opt.bse[0]/d_sigma     # standard error from regression\n",
    "\n",
    "# price SKU1\n",
    "B1_mu_P1_3    = results_3_opt.params[1]              # coefficient from regression\n",
    "B1_sigma_P1_3 = results_3_opt.bse[1]/d_sigma         # standard error from regression\n",
    "\n",
    "# price SKU3 \n",
    "B2_mu_P3_3    = results_3_opt.params[2]              # coefficient from regression\n",
    "B2_sigma_P3_3 = results_3_opt.bse[2]/d_sigma         # standard error from regression\n",
    "\n",
    "# feat2 SKU4\n",
    "B3_mu_P4_3    = results_3_opt.params[3]              # coefficient from regression\n",
    "B3_sigma_P4_3 = results_3_opt.bse[3]/d_sigma         # standard error from regression\n",
    "\n",
    "# disp3 SKU3\n",
    "B4_mu_D3_3 = results_3_opt.params[4]                 # coefficient from regression\n",
    "\n",
    "# feat3 SKU3\n",
    "B5_mu_F3_3 = results_3_opt.params[5]                 # coefficient from regression\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# Set up random draw parameters for coefficients - SKU4 (Sales)\n",
    "\n",
    "# intercept \n",
    "intercept_mu_4    = results_4_opt.params[0]          # coefficient from regression\n",
    "intercept_sigma_4 = results_4_opt.bse[0]/d_sigma     # standard error from regression\n",
    "\n",
    "# price SKU1\n",
    "B1_mu_P1_4    = results_4_opt.params[1]              # coefficient from regression\n",
    "B1_sigma_P1_4 = results_4_opt.bse[1]/d_sigma         # standard error from regression\n",
    "\n",
    "# price SKU3\n",
    "B2_mu_P3_4    = results_4_opt.params[2]              # coefficient from regression\n",
    "B2_sigma_P3_4 = results_4_opt.bse[2]/d_sigma         # standard error from regression\n",
    "\n",
    "# price  SKU4\n",
    "B3_mu_P4_4    = results_4_opt.params[3]              # coefficient from regression\n",
    "B3_sigma_P4_4 = results_4_opt.bse[3]/d_sigma         # standard error from regression\n",
    "\n",
    "# price SKU5\n",
    "B4_mu_P5_4    = results_4_opt.params[4]              # coefficient from regression\n",
    "B4_sigma_P5_4 = results_4_opt.bse[4]/d_sigma         # standard error from regression\n",
    "\n",
    "# disp4 SKU4\n",
    "B5_mu_D4_4 = results_4_opt.params[5]                 # coefficient from regression\n",
    "\n",
    "# feat4 SKU4\n",
    "B6_mu_F4_4 = results_4_opt.params[6]                 # coefficient from regression\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# Set up random draw parameters for coefficients - SKU5 (Sales)\n",
    "\n",
    "# intercept \n",
    "intercept_mu_5    = results_5_opt.params[0]          # coefficient from regression\n",
    "intercept_sigma_5 = results_5_opt.bse[0]/d_sigma     # standard error from regression\n",
    "\n",
    "# price SKU2\n",
    "B1_mu_P2_5    = results_5_opt.params[1]              # coefficient from regression\n",
    "B1_sigma_P2_5 = results_5_opt.bse[1]/d_sigma         # standard error from regression\n",
    "\n",
    "# price SKU3\n",
    "B2_mu_P3_5    = results_5_opt.params[2]              # coefficient from regression\n",
    "B2_sigma_P3_5 = results_5_opt.bse[2]/d_sigma         # standard error from regression\n",
    "\n",
    "# price SKU4\n",
    "B3_mu_P4_5    = results_5_opt.params[3]              # coefficient from regression\n",
    "B3_sigma_P4_5 = results_5_opt.bse[3]/d_sigma             # standard error from regression\n",
    "\n",
    "# price SKU5\n",
    "B4_mu_P5_5    = results_5_opt.params[4]              # coefficient from regression\n",
    "B4_sigma_P5_5 = results_5_opt.bse[4]/d_sigma         # standard error from regression\n",
    "\n",
    "# disp SKU5\n",
    "B5_mu_D5_5    = results_5_opt.params[5]              # coefficient from regression\n",
    "\n",
    "# feat5 SKU5\n",
    "B6_mu_F5_5    = results_5_opt.params[6]              # coefficient from regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "julian-glasgow",
   "metadata": {},
   "source": [
    "## Price & Marketing Settings Read and Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "behind-lightning",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T02:39:36.983582Z",
     "start_time": "2021-03-31T02:39:36.953661Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "all_settings = pd.read_csv('settings.csv')\n",
    "\n",
    "Top50 = all_settings.iloc[:2500,:] #jack \n",
    "#Bottom50 = all_settings.iloc[2500:,:] #max\n",
    "\n",
    "settings50 = Top50 \n",
    "#settings50 = Bottom50\n",
    "\n",
    "df_1 = settings50.iloc[:500,:]\n",
    "df_2 = settings50.iloc[500:1000,:]\n",
    "df_3 = settings50.iloc[1000:1500,:]\n",
    "df_4 = settings50.iloc[1500:2000,:]\n",
    "df_5 = settings50.iloc[2000:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-street",
   "metadata": {},
   "source": [
    "### N 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "photographic-cincinnati",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T02:39:36.989567Z",
     "start_time": "2021-03-31T02:39:36.985576Z"
    }
   },
   "outputs": [],
   "source": [
    "price_msettings_df = df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "linear-college",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T02:39:38.951159Z",
     "start_time": "2021-03-31T02:39:36.991560Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5ca7a6edf92477f83a0f5ea23fd7723",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Monte Carlo Simulation\n",
    "\n",
    "# (Re-) Setting Seed, due to np limitations\n",
    "np.random.seed(42)\n",
    "\n",
    "# Number of simulations per combinations of prices across SKUs'\n",
    "number_sims = 100_000\n",
    "\n",
    "# Store results from each simulation here\n",
    "final_stats = []\n",
    "\n",
    "# Loop over price dataframe\n",
    "for i in tqdm(range(len(price_msettings_df))):\n",
    "    \n",
    "    # Extract price per SKU as log\n",
    "    P_1 = np.log(price_msettings_df.iloc[i, 0])\n",
    "    P_2 = np.log(price_msettings_df.iloc[i, 1])\n",
    "    P_3 = np.log(price_msettings_df.iloc[i, 2])\n",
    "    P_4 = np.log(price_msettings_df.iloc[i, 3])\n",
    "    P_5 = np.log(price_msettings_df.iloc[i, 4])\n",
    "    \n",
    "    # Extract marketing settings per SKU \n",
    "    disp1 = price_msettings_df.iloc[i, 5]\n",
    "    disp2 = price_msettings_df.iloc[i, 6]\n",
    "    disp3 = price_msettings_df.iloc[i, 7]\n",
    "    disp4 = price_msettings_df.iloc[i, 8]\n",
    "    disp5 = price_msettings_df.iloc[i, 9]\n",
    "    \n",
    "    feat1 = price_msettings_df.iloc[i, 10]\n",
    "    feat2 = price_msettings_df.iloc[i, 11]\n",
    "    feat3 = price_msettings_df.iloc[i, 12]\n",
    "    feat4 = price_msettings_df.iloc[i, 13]\n",
    "    feat5 = price_msettings_df.iloc[i, 14]\n",
    "    \n",
    "    # Placeholder\n",
    "    all_stats = []\n",
    "\n",
    "    # Begin Simulation Loop\n",
    "    for i in range(number_sims):\n",
    "        \n",
    "        ###########\n",
    "        #  SKU1   # \n",
    "        ###########\n",
    "        \n",
    "        # Sales\n",
    "        intercept_1 = np.random.normal(intercept_mu_1, intercept_sigma_1)\n",
    "        B1_1   = np.random.normal(B1_mu_P1_1, B1_sigma_P1_1)\n",
    "        B2_1   = np.random.normal(B2_mu_P3_1, B2_sigma_P3_1)\n",
    "        \n",
    "        sales_1 = np.exp(intercept_1 \\\n",
    "                + B1_1 * P_1 \\\n",
    "                + B2_1 * P_3 \\\n",
    "                + B3_mu_D1_1 * disp1 \\\n",
    "                + B4_mu_F1_1 * feat1)\n",
    "        \n",
    "        # Gross Margin\n",
    "        intercept_GR1 = np.random.normal(intercept_mu_GR1, intercept_sigma_GR1)\n",
    "        B1_GR1   = np.random.normal(B1_mu_GR1, B1_sigma_GR1)\n",
    "        \n",
    "        grmar_1 = intercept_GR1 + B1_GR1 * P_1\n",
    "        \n",
    "        # Profit\n",
    "        revenue_1 = sales_1 * oz_1 * np.exp(P_1)\n",
    "        profits_1 = revenue_1 * grmar_1\n",
    "        \n",
    "        \n",
    "        ###########\n",
    "        #  SKU2   # \n",
    "        ###########\n",
    "\n",
    "        # Sales\n",
    "        intercept_2 = np.random.normal(intercept_mu_2, intercept_sigma_2)\n",
    "        B1_2   = np.random.normal(B1_mu_P1_2, B1_sigma_P1_2)\n",
    "        B2_2   = np.random.normal(B2_mu_P2_2, B2_sigma_P2_2)   \n",
    "        \n",
    "        sales_2 = np.exp(intercept_2 \\\n",
    "                + B1_2 * P_1 \\\n",
    "                + B2_2 * P_2 \\\n",
    "                + B3_mu_D2_2 * disp2 \\\n",
    "                + B4_mu_F2_2 * feat2)\n",
    "        \n",
    "        # Gross Margin\n",
    "        intercept_GR2 = np.random.normal(intercept_mu_GR2, intercept_sigma_GR2)\n",
    "        B1_GR2   = np.random.normal(B1_mu_GR2, B1_sigma_GR2)\n",
    "        \n",
    "        grmar_2 = intercept_GR2 + B1_GR2 * P_2\n",
    "        \n",
    "        # Profit\n",
    "        revenue_2 = sales_2 * oz_2 * np.exp(P_2)\n",
    "        profits_2 = revenue_2 * grmar_2\n",
    "        \n",
    "                \n",
    "        ###########\n",
    "        #  SKU3   # \n",
    "        ###########\n",
    "        \n",
    "        # Sales\n",
    "        intercept_3 = np.random.normal(intercept_mu_3, intercept_sigma_3)\n",
    "        B1_3   = np.random.normal(B1_mu_P1_3, B1_sigma_P1_3)\n",
    "        B2_3   = np.random.normal(B2_mu_P3_3, B2_sigma_P3_3)   \n",
    "        B3_3   = np.random.normal(B3_mu_P4_3, B3_sigma_P4_3) \n",
    "\n",
    "        sales_3 = np.exp(intercept_3 \\\n",
    "                + B1_3 * P_1 \\\n",
    "                + B2_3 * P_3 \\\n",
    "                + B3_3 * P_4 \\\n",
    "                + B4_mu_D3_3 * disp3 \\\n",
    "                + B5_mu_F3_3 * feat3)\n",
    "        \n",
    "        # Gross Margin\n",
    "        intercept_GR3 = np.random.normal(intercept_mu_GR3, intercept_sigma_GR3)\n",
    "        B1_GR3   = np.random.normal(B1_mu_GR3, B1_sigma_GR3)\n",
    "        \n",
    "        grmar_3 = intercept_GR3 + B1_GR3 * P_3\n",
    "        \n",
    "        # Profit\n",
    "        revenue_3 = sales_3 * oz_3 * np.exp(P_3)\n",
    "        profits_3 = revenue_3 * grmar_3\n",
    "        \n",
    "        \n",
    "        ###########\n",
    "        #  SKU4   # \n",
    "        ###########\n",
    "        \n",
    "        # Sales\n",
    "        intercept_4 = np.random.normal(intercept_mu_4, intercept_sigma_4)\n",
    "        B1_4   = np.random.normal(B1_mu_P1_4, B1_sigma_P1_4)\n",
    "        B2_4   = np.random.normal(B2_mu_P3_4, B2_sigma_P3_4)   \n",
    "        B3_4   = np.random.normal(B3_mu_P4_4, B3_sigma_P4_4) \n",
    "        B4_4   = np.random.normal(B4_mu_P5_4, B4_sigma_P5_4)\n",
    "        \n",
    "        sales_4 = np.exp(intercept_4 \\\n",
    "                + B1_4 * P_1 \\\n",
    "                + B2_4 * P_3 \\\n",
    "                + B3_4 * P_4 \\\n",
    "                + B4_4 * P_5 \\\n",
    "                + B5_mu_D4_4 * disp4 \\\n",
    "                + B6_mu_F4_4 * feat4)\n",
    "        \n",
    "        # Gross Margin\n",
    "        intercept_GR4 = np.random.normal(intercept_mu_GR4, intercept_sigma_GR4)\n",
    "        B1_GR4   = np.random.normal(B1_mu_GR4, B1_sigma_GR4)\n",
    "        \n",
    "        grmar_4 = intercept_GR4 + B1_GR4 * P_4\n",
    "        \n",
    "        # Profit\n",
    "        revenue_4 = sales_4 * oz_4 * np.exp(P_4)\n",
    "        profits_4 = revenue_4 * grmar_4\n",
    "        \n",
    "        \n",
    "        ###########\n",
    "        #  SKU5   # \n",
    "        ###########\n",
    "        \n",
    "        # Sales\n",
    "        intercept_5 = np.random.normal(intercept_mu_5, intercept_sigma_5)\n",
    "        B1_5   = np.random.normal(B1_mu_P2_5, B1_sigma_P2_5)\n",
    "        B2_5   = np.random.normal(B2_mu_P3_5, B2_sigma_P3_5)   \n",
    "        B3_5   = np.random.normal(B3_mu_P4_5, B3_sigma_P4_5) \n",
    "        B4_5   = np.random.normal(B4_mu_P5_5, B4_sigma_P5_5) \n",
    "        \n",
    "        sales_5 = np.exp(intercept_5 \\\n",
    "                + B1_5 * P_2 \\\n",
    "                + B2_5 * P_3 \\\n",
    "                + B3_5 * P_4 \\\n",
    "                + B4_5 * P_5 \\\n",
    "                + B5_mu_D5_5 * disp5 \\\n",
    "                + B6_mu_F5_5 * feat5)\n",
    "        \n",
    "        # Gross Margin\n",
    "        intercept_GR5 = np.random.normal(intercept_mu_GR5, intercept_sigma_GR5)\n",
    "        B1_GR5   = np.random.normal(B1_mu_GR5, B1_sigma_GR5)\n",
    "        \n",
    "        grmar_5 = intercept_GR5 + B1_GR5 * P_5\n",
    "        \n",
    "        # Profit\n",
    "        revenue_5 = sales_5 * oz_5 * np.exp(P_5)\n",
    "        profits_5 = revenue_5 * grmar_5\n",
    "        \n",
    "        \n",
    "        ####################\n",
    "        #  Appending SKUs  # \n",
    "        ####################\n",
    "        \n",
    "        all_stats.append([sales_1, revenue_1, profits_1, grmar_1,\n",
    "                          sales_2, revenue_2, profits_2, grmar_2,\n",
    "                          sales_3, revenue_3, profits_3, grmar_3,\n",
    "                          sales_4, revenue_4, profits_4, grmar_4,\n",
    "                          sales_5, revenue_5, profits_5, grmar_5])\n",
    "    \n",
    "    results_df = pd.DataFrame.from_records(all_stats,  columns = \n",
    "    ['units_sold_1','revenue_1','profits_1', 'grmar_1',\n",
    "     'units_sold_2','revenue_2','profits_2', 'grmar_2',\n",
    "     'units_sold_3','revenue_3','profits_3', 'grmar_3',\n",
    "     'units_sold_4','revenue_4','profits_4', 'grmar_4',\n",
    "     'units_sold_5','revenue_5','profits_5', 'grmar_5',])\n",
    "        \n",
    "    final_stats.append([np.exp(P_1), np.exp(P_2), np.exp(P_3),\n",
    "                        np.exp(P_4), np.exp(P_5),\n",
    "                        results_df['units_sold_1'].mean(),\n",
    "                        results_df['units_sold_2'].mean(),\n",
    "                        results_df['units_sold_3'].mean(),\n",
    "                        results_df['units_sold_4'].mean(),\n",
    "                        results_df['units_sold_5'].mean(),\n",
    "                        results_df['grmar_1'].mean(),\n",
    "                        results_df['grmar_2'].mean(),\n",
    "                        results_df['grmar_3'].mean(),\n",
    "                        results_df['grmar_4'].mean(),\n",
    "                        results_df['grmar_5'].mean(),\n",
    "                        results_df['profits_1'].mean(),\n",
    "                        results_df['profits_2'].mean(),\n",
    "                        results_df['profits_3'].mean(),\n",
    "                        results_df['profits_4'].mean(),\n",
    "                        results_df['profits_5'].mean(),\n",
    "                        feat1,feat2,feat3,feat4,feat5,\n",
    "                        disp1,disp2,disp3,disp4,disp5])\n",
    "    \n",
    "final_stats_df = pd.DataFrame.from_records(final_stats, columns =\n",
    "                ['Price per Oz_1', 'Price per Oz_2',\n",
    "                 'Price per Oz_3', 'Price per Oz_4', 'Price per Oz_5',\n",
    "                 'Sales_1', 'Sales_2', 'Sales_3', 'Sales_4', 'Sales_5',\n",
    "                 'GrMar_1', 'GrMar_2', 'GrMar_3', 'GrMar_4', 'GrMar_5',\n",
    "                 'Profits_1', 'Profits_2', \n",
    "                 'Profits_3', 'Profits_4', 'Profits_5',\n",
    "                 'Feat_1', 'Feat_2', 'Feat_3', 'Feat_4', 'Feat_5',\n",
    "                 'Disp_1', 'Disp_2', 'Disp_3', 'Disp_4', 'Disp_5'])\n",
    "\n",
    "final_stats_df['Total Profits'] = final_stats_df['Profits_5']\\\n",
    "                                + final_stats_df['Profits_4']\\\n",
    "                                + final_stats_df['Profits_3']\\\n",
    "                                + final_stats_df['Profits_2']\\\n",
    "                                + final_stats_df['Profits_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "angry-income",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T02:39:38.975129Z",
     "start_time": "2021-03-31T02:39:38.954150Z"
    }
   },
   "outputs": [],
   "source": [
    "df_1_stats = final_stats_df \n",
    "df_1_stats.to_csv('df_1_stats.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fuzzy-portfolio",
   "metadata": {},
   "source": [
    "### N 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "occupied-directive",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T02:39:38.983073Z",
     "start_time": "2021-03-31T02:39:38.979118Z"
    }
   },
   "outputs": [],
   "source": [
    "price_msettings_df = df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "regular-stevens",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T02:39:40.837302Z",
     "start_time": "2021-03-31T02:39:38.984105Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fb3120e532341078a82a3a1ab027413",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Monte Carlo Simulation\n",
    "\n",
    "# (Re-) Setting Seed, due to np limitations\n",
    "np.random.seed(42)\n",
    "\n",
    "# Number of simulations per combinations of prices across SKUs'\n",
    "number_sims = 100_000\n",
    "\n",
    "# Store results from each simulation here\n",
    "final_stats = []\n",
    "\n",
    "# Loop over price dataframe\n",
    "for i in tqdm(range(len(price_msettings_df))):\n",
    "    \n",
    "    # Extract price per SKU as log\n",
    "    P_1 = np.log(price_msettings_df.iloc[i, 0])\n",
    "    P_2 = np.log(price_msettings_df.iloc[i, 1])\n",
    "    P_3 = np.log(price_msettings_df.iloc[i, 2])\n",
    "    P_4 = np.log(price_msettings_df.iloc[i, 3])\n",
    "    P_5 = np.log(price_msettings_df.iloc[i, 4])\n",
    "    \n",
    "    # Extract marketing settings per SKU \n",
    "    disp1 = price_msettings_df.iloc[i, 5]\n",
    "    disp2 = price_msettings_df.iloc[i, 6]\n",
    "    disp3 = price_msettings_df.iloc[i, 7]\n",
    "    disp4 = price_msettings_df.iloc[i, 8]\n",
    "    disp5 = price_msettings_df.iloc[i, 9]\n",
    "    \n",
    "    feat1 = price_msettings_df.iloc[i, 10]\n",
    "    feat2 = price_msettings_df.iloc[i, 11]\n",
    "    feat3 = price_msettings_df.iloc[i, 12]\n",
    "    feat4 = price_msettings_df.iloc[i, 13]\n",
    "    feat5 = price_msettings_df.iloc[i, 14]\n",
    "    \n",
    "    # Placeholder\n",
    "    all_stats = []\n",
    "\n",
    "    # Begin Simulation Loop\n",
    "    for i in range(number_sims):\n",
    "        \n",
    "        ###########\n",
    "        #  SKU1   # \n",
    "        ###########\n",
    "        \n",
    "        # Sales\n",
    "        intercept_1 = np.random.normal(intercept_mu_1, intercept_sigma_1)\n",
    "        B1_1   = np.random.normal(B1_mu_P1_1, B1_sigma_P1_1)\n",
    "        B2_1   = np.random.normal(B2_mu_P3_1, B2_sigma_P3_1)\n",
    "        \n",
    "        sales_1 = np.exp(intercept_1 \\\n",
    "                + B1_1 * P_1 \\\n",
    "                + B2_1 * P_3 \\\n",
    "                + B3_mu_D1_1 * disp1 \\\n",
    "                + B4_mu_F1_1 * feat1)\n",
    "        \n",
    "        # Gross Margin\n",
    "        intercept_GR1 = np.random.normal(intercept_mu_GR1, intercept_sigma_GR1)\n",
    "        B1_GR1   = np.random.normal(B1_mu_GR1, B1_sigma_GR1)\n",
    "        \n",
    "        grmar_1 = intercept_GR1 + B1_GR1 * P_1\n",
    "        \n",
    "        # Profit\n",
    "        revenue_1 = sales_1 * oz_1 * np.exp(P_1)\n",
    "        profits_1 = revenue_1 * grmar_1\n",
    "        \n",
    "        \n",
    "        ###########\n",
    "        #  SKU2   # \n",
    "        ###########\n",
    "\n",
    "        # Sales\n",
    "        intercept_2 = np.random.normal(intercept_mu_2, intercept_sigma_2)\n",
    "        B1_2   = np.random.normal(B1_mu_P1_2, B1_sigma_P1_2)\n",
    "        B2_2   = np.random.normal(B2_mu_P2_2, B2_sigma_P2_2)   \n",
    "        \n",
    "        sales_2 = np.exp(intercept_2 \\\n",
    "                + B1_2 * P_1 \\\n",
    "                + B2_2 * P_2 \\\n",
    "                + B3_mu_D2_2 * disp2 \\\n",
    "                + B4_mu_F2_2 * feat2)\n",
    "        \n",
    "        # Gross Margin\n",
    "        intercept_GR2 = np.random.normal(intercept_mu_GR2, intercept_sigma_GR2)\n",
    "        B1_GR2   = np.random.normal(B1_mu_GR2, B1_sigma_GR2)\n",
    "        \n",
    "        grmar_2 = intercept_GR2 + B1_GR2 * P_2\n",
    "        \n",
    "        # Profit\n",
    "        revenue_2 = sales_2 * oz_2 * np.exp(P_2)\n",
    "        profits_2 = revenue_2 * grmar_2\n",
    "        \n",
    "                \n",
    "        ###########\n",
    "        #  SKU3   # \n",
    "        ###########\n",
    "        \n",
    "        # Sales\n",
    "        intercept_3 = np.random.normal(intercept_mu_3, intercept_sigma_3)\n",
    "        B1_3   = np.random.normal(B1_mu_P1_3, B1_sigma_P1_3)\n",
    "        B2_3   = np.random.normal(B2_mu_P3_3, B2_sigma_P3_3)   \n",
    "        B3_3   = np.random.normal(B3_mu_P4_3, B3_sigma_P4_3) \n",
    "\n",
    "        sales_3 = np.exp(intercept_3 \\\n",
    "                + B1_3 * P_1 \\\n",
    "                + B2_3 * P_3 \\\n",
    "                + B3_3 * P_4 \\\n",
    "                + B4_mu_D3_3 * disp3 \\\n",
    "                + B5_mu_F3_3 * feat3)\n",
    "        \n",
    "        # Gross Margin\n",
    "        intercept_GR3 = np.random.normal(intercept_mu_GR3, intercept_sigma_GR3)\n",
    "        B1_GR3   = np.random.normal(B1_mu_GR3, B1_sigma_GR3)\n",
    "        \n",
    "        grmar_3 = intercept_GR3 + B1_GR3 * P_3\n",
    "        \n",
    "        # Profit\n",
    "        revenue_3 = sales_3 * oz_3 * np.exp(P_3)\n",
    "        profits_3 = revenue_3 * grmar_3\n",
    "        \n",
    "        \n",
    "        ###########\n",
    "        #  SKU4   # \n",
    "        ###########\n",
    "        \n",
    "        # Sales\n",
    "        intercept_4 = np.random.normal(intercept_mu_4, intercept_sigma_4)\n",
    "        B1_4   = np.random.normal(B1_mu_P1_4, B1_sigma_P1_4)\n",
    "        B2_4   = np.random.normal(B2_mu_P3_4, B2_sigma_P3_4)   \n",
    "        B3_4   = np.random.normal(B3_mu_P4_4, B3_sigma_P4_4) \n",
    "        B4_4   = np.random.normal(B4_mu_P5_4, B4_sigma_P5_4)\n",
    "        \n",
    "        sales_4 = np.exp(intercept_4 \\\n",
    "                + B1_4 * P_1 \\\n",
    "                + B2_4 * P_3 \\\n",
    "                + B3_4 * P_4 \\\n",
    "                + B4_4 * P_5 \\\n",
    "                + B5_mu_D4_4 * disp4 \\\n",
    "                + B6_mu_F4_4 * feat4)\n",
    "        \n",
    "        # Gross Margin\n",
    "        intercept_GR4 = np.random.normal(intercept_mu_GR4, intercept_sigma_GR4)\n",
    "        B1_GR4   = np.random.normal(B1_mu_GR4, B1_sigma_GR4)\n",
    "        \n",
    "        grmar_4 = intercept_GR4 + B1_GR4 * P_4\n",
    "        \n",
    "        # Profit\n",
    "        revenue_4 = sales_4 * oz_4 * np.exp(P_4)\n",
    "        profits_4 = revenue_4 * grmar_4\n",
    "        \n",
    "        \n",
    "        ###########\n",
    "        #  SKU5   # \n",
    "        ###########\n",
    "        \n",
    "        # Sales\n",
    "        intercept_5 = np.random.normal(intercept_mu_5, intercept_sigma_5)\n",
    "        B1_5   = np.random.normal(B1_mu_P2_5, B1_sigma_P2_5)\n",
    "        B2_5   = np.random.normal(B2_mu_P3_5, B2_sigma_P3_5)   \n",
    "        B3_5   = np.random.normal(B3_mu_P4_5, B3_sigma_P4_5) \n",
    "        B4_5   = np.random.normal(B4_mu_P5_5, B4_sigma_P5_5) \n",
    "        \n",
    "        sales_5 = np.exp(intercept_5 \\\n",
    "                + B1_5 * P_2 \\\n",
    "                + B2_5 * P_3 \\\n",
    "                + B3_5 * P_4 \\\n",
    "                + B4_5 * P_5 \\\n",
    "                + B5_mu_D5_5 * disp5 \\\n",
    "                + B6_mu_F5_5 * feat5)\n",
    "        \n",
    "        # Gross Margin\n",
    "        intercept_GR5 = np.random.normal(intercept_mu_GR5, intercept_sigma_GR5)\n",
    "        B1_GR5   = np.random.normal(B1_mu_GR5, B1_sigma_GR5)\n",
    "        \n",
    "        grmar_5 = intercept_GR5 + B1_GR5 * P_5\n",
    "        \n",
    "        # Profit\n",
    "        revenue_5 = sales_5 * oz_5 * np.exp(P_5)\n",
    "        profits_5 = revenue_5 * grmar_5\n",
    "        \n",
    "        \n",
    "        ####################\n",
    "        #  Appending SKUs  # \n",
    "        ####################\n",
    "        \n",
    "        all_stats.append([sales_1, revenue_1, profits_1, grmar_1,\n",
    "                          sales_2, revenue_2, profits_2, grmar_2,\n",
    "                          sales_3, revenue_3, profits_3, grmar_3,\n",
    "                          sales_4, revenue_4, profits_4, grmar_4,\n",
    "                          sales_5, revenue_5, profits_5, grmar_5])\n",
    "    \n",
    "    results_df = pd.DataFrame.from_records(all_stats,  columns = \n",
    "    ['units_sold_1','revenue_1','profits_1', 'grmar_1',\n",
    "     'units_sold_2','revenue_2','profits_2', 'grmar_2',\n",
    "     'units_sold_3','revenue_3','profits_3', 'grmar_3',\n",
    "     'units_sold_4','revenue_4','profits_4', 'grmar_4',\n",
    "     'units_sold_5','revenue_5','profits_5', 'grmar_5',])\n",
    "        \n",
    "    final_stats.append([np.exp(P_1), np.exp(P_2), np.exp(P_3),\n",
    "                        np.exp(P_4), np.exp(P_5),\n",
    "                        results_df['units_sold_1'].mean(),\n",
    "                        results_df['units_sold_2'].mean(),\n",
    "                        results_df['units_sold_3'].mean(),\n",
    "                        results_df['units_sold_4'].mean(),\n",
    "                        results_df['units_sold_5'].mean(),\n",
    "                        results_df['grmar_1'].mean(),\n",
    "                        results_df['grmar_2'].mean(),\n",
    "                        results_df['grmar_3'].mean(),\n",
    "                        results_df['grmar_4'].mean(),\n",
    "                        results_df['grmar_5'].mean(),\n",
    "                        results_df['profits_1'].mean(),\n",
    "                        results_df['profits_2'].mean(),\n",
    "                        results_df['profits_3'].mean(),\n",
    "                        results_df['profits_4'].mean(),\n",
    "                        results_df['profits_5'].mean(),\n",
    "                        feat1,feat2,feat3,feat4,feat5,\n",
    "                        disp1,disp2,disp3,disp4,disp5])\n",
    "    \n",
    "final_stats_df = pd.DataFrame.from_records(final_stats, columns =\n",
    "                ['Price per Oz_1', 'Price per Oz_2',\n",
    "                 'Price per Oz_3', 'Price per Oz_4', 'Price per Oz_5',\n",
    "                 'Sales_1', 'Sales_2', 'Sales_3', 'Sales_4', 'Sales_5',\n",
    "                 'GrMar_1', 'GrMar_2', 'GrMar_3', 'GrMar_4', 'GrMar_5',\n",
    "                 'Profits_1', 'Profits_2', \n",
    "                 'Profits_3', 'Profits_4', 'Profits_5',\n",
    "                 'Feat_1', 'Feat_2', 'Feat_3', 'Feat_4', 'Feat_5',\n",
    "                 'Disp_1', 'Disp_2', 'Disp_3', 'Disp_4', 'Disp_5'])\n",
    "\n",
    "final_stats_df['Total Profits'] = final_stats_df['Profits_5']\\\n",
    "                                + final_stats_df['Profits_4']\\\n",
    "                                + final_stats_df['Profits_3']\\\n",
    "                                + final_stats_df['Profits_2']\\\n",
    "                                + final_stats_df['Profits_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "disabled-malawi",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T02:39:40.857275Z",
     "start_time": "2021-03-31T02:39:40.838295Z"
    }
   },
   "outputs": [],
   "source": [
    "df_2_stats = final_stats_df \n",
    "df_2_stats.to_csv('df_2_stats.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinate-forth",
   "metadata": {},
   "source": [
    "### N 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "sharing-penny",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T02:39:40.861232Z",
     "start_time": "2021-03-31T02:39:40.858271Z"
    }
   },
   "outputs": [],
   "source": [
    "price_msettings_df = df_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "accredited-citizen",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T02:39:42.761104Z",
     "start_time": "2021-03-31T02:39:40.862228Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4344a4c043b45a9b460293325a0d93a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Monte Carlo Simulation\n",
    "\n",
    "# (Re-) Setting Seed, due to np limitations\n",
    "np.random.seed(42)\n",
    "\n",
    "# Number of simulations per combinations of prices across SKUs'\n",
    "number_sims = 100_000\n",
    "\n",
    "# Store results from each simulation here\n",
    "final_stats = []\n",
    "\n",
    "# Loop over price dataframe\n",
    "for i in tqdm(range(len(price_msettings_df))):\n",
    "    \n",
    "    # Extract price per SKU as log\n",
    "    P_1 = np.log(price_msettings_df.iloc[i, 0])\n",
    "    P_2 = np.log(price_msettings_df.iloc[i, 1])\n",
    "    P_3 = np.log(price_msettings_df.iloc[i, 2])\n",
    "    P_4 = np.log(price_msettings_df.iloc[i, 3])\n",
    "    P_5 = np.log(price_msettings_df.iloc[i, 4])\n",
    "    \n",
    "    # Extract marketing settings per SKU \n",
    "    disp1 = price_msettings_df.iloc[i, 5]\n",
    "    disp2 = price_msettings_df.iloc[i, 6]\n",
    "    disp3 = price_msettings_df.iloc[i, 7]\n",
    "    disp4 = price_msettings_df.iloc[i, 8]\n",
    "    disp5 = price_msettings_df.iloc[i, 9]\n",
    "    \n",
    "    feat1 = price_msettings_df.iloc[i, 10]\n",
    "    feat2 = price_msettings_df.iloc[i, 11]\n",
    "    feat3 = price_msettings_df.iloc[i, 12]\n",
    "    feat4 = price_msettings_df.iloc[i, 13]\n",
    "    feat5 = price_msettings_df.iloc[i, 14]\n",
    "    \n",
    "    # Placeholder\n",
    "    all_stats = []\n",
    "\n",
    "    # Begin Simulation Loop\n",
    "    for i in range(number_sims):\n",
    "        \n",
    "        ###########\n",
    "        #  SKU1   # \n",
    "        ###########\n",
    "        \n",
    "        # Sales\n",
    "        intercept_1 = np.random.normal(intercept_mu_1, intercept_sigma_1)\n",
    "        B1_1   = np.random.normal(B1_mu_P1_1, B1_sigma_P1_1)\n",
    "        B2_1   = np.random.normal(B2_mu_P3_1, B2_sigma_P3_1)\n",
    "        \n",
    "        sales_1 = np.exp(intercept_1 \\\n",
    "                + B1_1 * P_1 \\\n",
    "                + B2_1 * P_3 \\\n",
    "                + B3_mu_D1_1 * disp1 \\\n",
    "                + B4_mu_F1_1 * feat1)\n",
    "        \n",
    "        # Gross Margin\n",
    "        intercept_GR1 = np.random.normal(intercept_mu_GR1, intercept_sigma_GR1)\n",
    "        B1_GR1   = np.random.normal(B1_mu_GR1, B1_sigma_GR1)\n",
    "        \n",
    "        grmar_1 = intercept_GR1 + B1_GR1 * P_1\n",
    "        \n",
    "        # Profit\n",
    "        revenue_1 = sales_1 * oz_1 * np.exp(P_1)\n",
    "        profits_1 = revenue_1 * grmar_1\n",
    "        \n",
    "        \n",
    "        ###########\n",
    "        #  SKU2   # \n",
    "        ###########\n",
    "\n",
    "        # Sales\n",
    "        intercept_2 = np.random.normal(intercept_mu_2, intercept_sigma_2)\n",
    "        B1_2   = np.random.normal(B1_mu_P1_2, B1_sigma_P1_2)\n",
    "        B2_2   = np.random.normal(B2_mu_P2_2, B2_sigma_P2_2)   \n",
    "        \n",
    "        sales_2 = np.exp(intercept_2 \\\n",
    "                + B1_2 * P_1 \\\n",
    "                + B2_2 * P_2 \\\n",
    "                + B3_mu_D2_2 * disp2 \\\n",
    "                + B4_mu_F2_2 * feat2)\n",
    "        \n",
    "        # Gross Margin\n",
    "        intercept_GR2 = np.random.normal(intercept_mu_GR2, intercept_sigma_GR2)\n",
    "        B1_GR2   = np.random.normal(B1_mu_GR2, B1_sigma_GR2)\n",
    "        \n",
    "        grmar_2 = intercept_GR2 + B1_GR2 * P_2\n",
    "        \n",
    "        # Profit\n",
    "        revenue_2 = sales_2 * oz_2 * np.exp(P_2)\n",
    "        profits_2 = revenue_2 * grmar_2\n",
    "        \n",
    "                \n",
    "        ###########\n",
    "        #  SKU3   # \n",
    "        ###########\n",
    "        \n",
    "        # Sales\n",
    "        intercept_3 = np.random.normal(intercept_mu_3, intercept_sigma_3)\n",
    "        B1_3   = np.random.normal(B1_mu_P1_3, B1_sigma_P1_3)\n",
    "        B2_3   = np.random.normal(B2_mu_P3_3, B2_sigma_P3_3)   \n",
    "        B3_3   = np.random.normal(B3_mu_P4_3, B3_sigma_P4_3) \n",
    "\n",
    "        sales_3 = np.exp(intercept_3 \\\n",
    "                + B1_3 * P_1 \\\n",
    "                + B2_3 * P_3 \\\n",
    "                + B3_3 * P_4 \\\n",
    "                + B4_mu_D3_3 * disp3 \\\n",
    "                + B5_mu_F3_3 * feat3)\n",
    "        \n",
    "        # Gross Margin\n",
    "        intercept_GR3 = np.random.normal(intercept_mu_GR3, intercept_sigma_GR3)\n",
    "        B1_GR3   = np.random.normal(B1_mu_GR3, B1_sigma_GR3)\n",
    "        \n",
    "        grmar_3 = intercept_GR3 + B1_GR3 * P_3\n",
    "        \n",
    "        # Profit\n",
    "        revenue_3 = sales_3 * oz_3 * np.exp(P_3)\n",
    "        profits_3 = revenue_3 * grmar_3\n",
    "        \n",
    "        \n",
    "        ###########\n",
    "        #  SKU4   # \n",
    "        ###########\n",
    "        \n",
    "        # Sales\n",
    "        intercept_4 = np.random.normal(intercept_mu_4, intercept_sigma_4)\n",
    "        B1_4   = np.random.normal(B1_mu_P1_4, B1_sigma_P1_4)\n",
    "        B2_4   = np.random.normal(B2_mu_P3_4, B2_sigma_P3_4)   \n",
    "        B3_4   = np.random.normal(B3_mu_P4_4, B3_sigma_P4_4) \n",
    "        B4_4   = np.random.normal(B4_mu_P5_4, B4_sigma_P5_4)\n",
    "        \n",
    "        sales_4 = np.exp(intercept_4 \\\n",
    "                + B1_4 * P_1 \\\n",
    "                + B2_4 * P_3 \\\n",
    "                + B3_4 * P_4 \\\n",
    "                + B4_4 * P_5 \\\n",
    "                + B5_mu_D4_4 * disp4 \\\n",
    "                + B6_mu_F4_4 * feat4)\n",
    "        \n",
    "        # Gross Margin\n",
    "        intercept_GR4 = np.random.normal(intercept_mu_GR4, intercept_sigma_GR4)\n",
    "        B1_GR4   = np.random.normal(B1_mu_GR4, B1_sigma_GR4)\n",
    "        \n",
    "        grmar_4 = intercept_GR4 + B1_GR4 * P_4\n",
    "        \n",
    "        # Profit\n",
    "        revenue_4 = sales_4 * oz_4 * np.exp(P_4)\n",
    "        profits_4 = revenue_4 * grmar_4\n",
    "        \n",
    "        \n",
    "        ###########\n",
    "        #  SKU5   # \n",
    "        ###########\n",
    "        \n",
    "        # Sales\n",
    "        intercept_5 = np.random.normal(intercept_mu_5, intercept_sigma_5)\n",
    "        B1_5   = np.random.normal(B1_mu_P2_5, B1_sigma_P2_5)\n",
    "        B2_5   = np.random.normal(B2_mu_P3_5, B2_sigma_P3_5)   \n",
    "        B3_5   = np.random.normal(B3_mu_P4_5, B3_sigma_P4_5) \n",
    "        B4_5   = np.random.normal(B4_mu_P5_5, B4_sigma_P5_5) \n",
    "        \n",
    "        sales_5 = np.exp(intercept_5 \\\n",
    "                + B1_5 * P_2 \\\n",
    "                + B2_5 * P_3 \\\n",
    "                + B3_5 * P_4 \\\n",
    "                + B4_5 * P_5 \\\n",
    "                + B5_mu_D5_5 * disp5 \\\n",
    "                + B6_mu_F5_5 * feat5)\n",
    "        \n",
    "        # Gross Margin\n",
    "        intercept_GR5 = np.random.normal(intercept_mu_GR5, intercept_sigma_GR5)\n",
    "        B1_GR5   = np.random.normal(B1_mu_GR5, B1_sigma_GR5)\n",
    "        \n",
    "        grmar_5 = intercept_GR5 + B1_GR5 * P_5\n",
    "        \n",
    "        # Profit\n",
    "        revenue_5 = sales_5 * oz_5 * np.exp(P_5)\n",
    "        profits_5 = revenue_5 * grmar_5\n",
    "        \n",
    "        \n",
    "        ####################\n",
    "        #  Appending SKUs  # \n",
    "        ####################\n",
    "        \n",
    "        all_stats.append([sales_1, revenue_1, profits_1, grmar_1,\n",
    "                          sales_2, revenue_2, profits_2, grmar_2,\n",
    "                          sales_3, revenue_3, profits_3, grmar_3,\n",
    "                          sales_4, revenue_4, profits_4, grmar_4,\n",
    "                          sales_5, revenue_5, profits_5, grmar_5])\n",
    "    \n",
    "    results_df = pd.DataFrame.from_records(all_stats,  columns = \n",
    "    ['units_sold_1','revenue_1','profits_1', 'grmar_1',\n",
    "     'units_sold_2','revenue_2','profits_2', 'grmar_2',\n",
    "     'units_sold_3','revenue_3','profits_3', 'grmar_3',\n",
    "     'units_sold_4','revenue_4','profits_4', 'grmar_4',\n",
    "     'units_sold_5','revenue_5','profits_5', 'grmar_5',])\n",
    "        \n",
    "    final_stats.append([np.exp(P_1), np.exp(P_2), np.exp(P_3),\n",
    "                        np.exp(P_4), np.exp(P_5),\n",
    "                        results_df['units_sold_1'].mean(),\n",
    "                        results_df['units_sold_2'].mean(),\n",
    "                        results_df['units_sold_3'].mean(),\n",
    "                        results_df['units_sold_4'].mean(),\n",
    "                        results_df['units_sold_5'].mean(),\n",
    "                        results_df['grmar_1'].mean(),\n",
    "                        results_df['grmar_2'].mean(),\n",
    "                        results_df['grmar_3'].mean(),\n",
    "                        results_df['grmar_4'].mean(),\n",
    "                        results_df['grmar_5'].mean(),\n",
    "                        results_df['profits_1'].mean(),\n",
    "                        results_df['profits_2'].mean(),\n",
    "                        results_df['profits_3'].mean(),\n",
    "                        results_df['profits_4'].mean(),\n",
    "                        results_df['profits_5'].mean(),\n",
    "                        feat1,feat2,feat3,feat4,feat5,\n",
    "                        disp1,disp2,disp3,disp4,disp5])\n",
    "    \n",
    "final_stats_df = pd.DataFrame.from_records(final_stats, columns =\n",
    "                ['Price per Oz_1', 'Price per Oz_2',\n",
    "                 'Price per Oz_3', 'Price per Oz_4', 'Price per Oz_5',\n",
    "                 'Sales_1', 'Sales_2', 'Sales_3', 'Sales_4', 'Sales_5',\n",
    "                 'GrMar_1', 'GrMar_2', 'GrMar_3', 'GrMar_4', 'GrMar_5',\n",
    "                 'Profits_1', 'Profits_2', \n",
    "                 'Profits_3', 'Profits_4', 'Profits_5',\n",
    "                 'Feat_1', 'Feat_2', 'Feat_3', 'Feat_4', 'Feat_5',\n",
    "                 'Disp_1', 'Disp_2', 'Disp_3', 'Disp_4', 'Disp_5'])\n",
    "\n",
    "final_stats_df['Total Profits'] = final_stats_df['Profits_5']\\\n",
    "                                + final_stats_df['Profits_4']\\\n",
    "                                + final_stats_df['Profits_3']\\\n",
    "                                + final_stats_df['Profits_2']\\\n",
    "                                + final_stats_df['Profits_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "damaged-toronto",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T02:39:42.783045Z",
     "start_time": "2021-03-31T02:39:42.762101Z"
    }
   },
   "outputs": [],
   "source": [
    "df_3_stats = final_stats_df \n",
    "df_3_stats.to_csv('df_3_stats.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stylish-october",
   "metadata": {},
   "source": [
    "### N 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "statutory-diesel",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T02:39:42.787037Z",
     "start_time": "2021-03-31T02:39:42.784077Z"
    }
   },
   "outputs": [],
   "source": [
    "price_msettings_df = df_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "theoretical-princeton",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T02:39:44.826829Z",
     "start_time": "2021-03-31T02:39:42.789030Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d09e39bd6ed540e69c20384455187af9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Monte Carlo Simulation\n",
    "\n",
    "# (Re-) Setting Seed, due to np limitations\n",
    "np.random.seed(42)\n",
    "\n",
    "# Number of simulations per combinations of prices across SKUs'\n",
    "number_sims = 100_000\n",
    "\n",
    "# Store results from each simulation here\n",
    "final_stats = []\n",
    "\n",
    "# Loop over price dataframe\n",
    "for i in tqdm(range(len(price_msettings_df))):\n",
    "    \n",
    "    # Extract price per SKU as log\n",
    "    P_1 = np.log(price_msettings_df.iloc[i, 0])\n",
    "    P_2 = np.log(price_msettings_df.iloc[i, 1])\n",
    "    P_3 = np.log(price_msettings_df.iloc[i, 2])\n",
    "    P_4 = np.log(price_msettings_df.iloc[i, 3])\n",
    "    P_5 = np.log(price_msettings_df.iloc[i, 4])\n",
    "    \n",
    "    # Extract marketing settings per SKU \n",
    "    disp1 = price_msettings_df.iloc[i, 5]\n",
    "    disp2 = price_msettings_df.iloc[i, 6]\n",
    "    disp3 = price_msettings_df.iloc[i, 7]\n",
    "    disp4 = price_msettings_df.iloc[i, 8]\n",
    "    disp5 = price_msettings_df.iloc[i, 9]\n",
    "    \n",
    "    feat1 = price_msettings_df.iloc[i, 10]\n",
    "    feat2 = price_msettings_df.iloc[i, 11]\n",
    "    feat3 = price_msettings_df.iloc[i, 12]\n",
    "    feat4 = price_msettings_df.iloc[i, 13]\n",
    "    feat5 = price_msettings_df.iloc[i, 14]\n",
    "    \n",
    "    # Placeholder\n",
    "    all_stats = []\n",
    "\n",
    "    # Begin Simulation Loop\n",
    "    for i in range(number_sims):\n",
    "        \n",
    "        ###########\n",
    "        #  SKU1   # \n",
    "        ###########\n",
    "        \n",
    "        # Sales\n",
    "        intercept_1 = np.random.normal(intercept_mu_1, intercept_sigma_1)\n",
    "        B1_1   = np.random.normal(B1_mu_P1_1, B1_sigma_P1_1)\n",
    "        B2_1   = np.random.normal(B2_mu_P3_1, B2_sigma_P3_1)\n",
    "        \n",
    "        sales_1 = np.exp(intercept_1 \\\n",
    "                + B1_1 * P_1 \\\n",
    "                + B2_1 * P_3 \\\n",
    "                + B3_mu_D1_1 * disp1 \\\n",
    "                + B4_mu_F1_1 * feat1)\n",
    "        \n",
    "        # Gross Margin\n",
    "        intercept_GR1 = np.random.normal(intercept_mu_GR1, intercept_sigma_GR1)\n",
    "        B1_GR1   = np.random.normal(B1_mu_GR1, B1_sigma_GR1)\n",
    "        \n",
    "        grmar_1 = intercept_GR1 + B1_GR1 * P_1\n",
    "        \n",
    "        # Profit\n",
    "        revenue_1 = sales_1 * oz_1 * np.exp(P_1)\n",
    "        profits_1 = revenue_1 * grmar_1\n",
    "        \n",
    "        \n",
    "        ###########\n",
    "        #  SKU2   # \n",
    "        ###########\n",
    "\n",
    "        # Sales\n",
    "        intercept_2 = np.random.normal(intercept_mu_2, intercept_sigma_2)\n",
    "        B1_2   = np.random.normal(B1_mu_P1_2, B1_sigma_P1_2)\n",
    "        B2_2   = np.random.normal(B2_mu_P2_2, B2_sigma_P2_2)   \n",
    "        \n",
    "        sales_2 = np.exp(intercept_2 \\\n",
    "                + B1_2 * P_1 \\\n",
    "                + B2_2 * P_2 \\\n",
    "                + B3_mu_D2_2 * disp2 \\\n",
    "                + B4_mu_F2_2 * feat2)\n",
    "        \n",
    "        # Gross Margin\n",
    "        intercept_GR2 = np.random.normal(intercept_mu_GR2, intercept_sigma_GR2)\n",
    "        B1_GR2   = np.random.normal(B1_mu_GR2, B1_sigma_GR2)\n",
    "        \n",
    "        grmar_2 = intercept_GR2 + B1_GR2 * P_2\n",
    "        \n",
    "        # Profit\n",
    "        revenue_2 = sales_2 * oz_2 * np.exp(P_2)\n",
    "        profits_2 = revenue_2 * grmar_2\n",
    "        \n",
    "                \n",
    "        ###########\n",
    "        #  SKU3   # \n",
    "        ###########\n",
    "        \n",
    "        # Sales\n",
    "        intercept_3 = np.random.normal(intercept_mu_3, intercept_sigma_3)\n",
    "        B1_3   = np.random.normal(B1_mu_P1_3, B1_sigma_P1_3)\n",
    "        B2_3   = np.random.normal(B2_mu_P3_3, B2_sigma_P3_3)   \n",
    "        B3_3   = np.random.normal(B3_mu_P4_3, B3_sigma_P4_3) \n",
    "\n",
    "        sales_3 = np.exp(intercept_3 \\\n",
    "                + B1_3 * P_1 \\\n",
    "                + B2_3 * P_3 \\\n",
    "                + B3_3 * P_4 \\\n",
    "                + B4_mu_D3_3 * disp3 \\\n",
    "                + B5_mu_F3_3 * feat3)\n",
    "        \n",
    "        # Gross Margin\n",
    "        intercept_GR3 = np.random.normal(intercept_mu_GR3, intercept_sigma_GR3)\n",
    "        B1_GR3   = np.random.normal(B1_mu_GR3, B1_sigma_GR3)\n",
    "        \n",
    "        grmar_3 = intercept_GR3 + B1_GR3 * P_3\n",
    "        \n",
    "        # Profit\n",
    "        revenue_3 = sales_3 * oz_3 * np.exp(P_3)\n",
    "        profits_3 = revenue_3 * grmar_3\n",
    "        \n",
    "        \n",
    "        ###########\n",
    "        #  SKU4   # \n",
    "        ###########\n",
    "        \n",
    "        # Sales\n",
    "        intercept_4 = np.random.normal(intercept_mu_4, intercept_sigma_4)\n",
    "        B1_4   = np.random.normal(B1_mu_P1_4, B1_sigma_P1_4)\n",
    "        B2_4   = np.random.normal(B2_mu_P3_4, B2_sigma_P3_4)   \n",
    "        B3_4   = np.random.normal(B3_mu_P4_4, B3_sigma_P4_4) \n",
    "        B4_4   = np.random.normal(B4_mu_P5_4, B4_sigma_P5_4)\n",
    "        \n",
    "        sales_4 = np.exp(intercept_4 \\\n",
    "                + B1_4 * P_1 \\\n",
    "                + B2_4 * P_3 \\\n",
    "                + B3_4 * P_4 \\\n",
    "                + B4_4 * P_5 \\\n",
    "                + B5_mu_D4_4 * disp4 \\\n",
    "                + B6_mu_F4_4 * feat4)\n",
    "        \n",
    "        # Gross Margin\n",
    "        intercept_GR4 = np.random.normal(intercept_mu_GR4, intercept_sigma_GR4)\n",
    "        B1_GR4   = np.random.normal(B1_mu_GR4, B1_sigma_GR4)\n",
    "        \n",
    "        grmar_4 = intercept_GR4 + B1_GR4 * P_4\n",
    "        \n",
    "        # Profit\n",
    "        revenue_4 = sales_4 * oz_4 * np.exp(P_4)\n",
    "        profits_4 = revenue_4 * grmar_4\n",
    "        \n",
    "        \n",
    "        ###########\n",
    "        #  SKU5   # \n",
    "        ###########\n",
    "        \n",
    "        # Sales\n",
    "        intercept_5 = np.random.normal(intercept_mu_5, intercept_sigma_5)\n",
    "        B1_5   = np.random.normal(B1_mu_P2_5, B1_sigma_P2_5)\n",
    "        B2_5   = np.random.normal(B2_mu_P3_5, B2_sigma_P3_5)   \n",
    "        B3_5   = np.random.normal(B3_mu_P4_5, B3_sigma_P4_5) \n",
    "        B4_5   = np.random.normal(B4_mu_P5_5, B4_sigma_P5_5) \n",
    "        \n",
    "        sales_5 = np.exp(intercept_5 \\\n",
    "                + B1_5 * P_2 \\\n",
    "                + B2_5 * P_3 \\\n",
    "                + B3_5 * P_4 \\\n",
    "                + B4_5 * P_5 \\\n",
    "                + B5_mu_D5_5 * disp5 \\\n",
    "                + B6_mu_F5_5 * feat5)\n",
    "        \n",
    "        # Gross Margin\n",
    "        intercept_GR5 = np.random.normal(intercept_mu_GR5, intercept_sigma_GR5)\n",
    "        B1_GR5   = np.random.normal(B1_mu_GR5, B1_sigma_GR5)\n",
    "        \n",
    "        grmar_5 = intercept_GR5 + B1_GR5 * P_5\n",
    "        \n",
    "        # Profit\n",
    "        revenue_5 = sales_5 * oz_5 * np.exp(P_5)\n",
    "        profits_5 = revenue_5 * grmar_5\n",
    "        \n",
    "        \n",
    "        ####################\n",
    "        #  Appending SKUs  # \n",
    "        ####################\n",
    "        \n",
    "        all_stats.append([sales_1, revenue_1, profits_1, grmar_1,\n",
    "                          sales_2, revenue_2, profits_2, grmar_2,\n",
    "                          sales_3, revenue_3, profits_3, grmar_3,\n",
    "                          sales_4, revenue_4, profits_4, grmar_4,\n",
    "                          sales_5, revenue_5, profits_5, grmar_5])\n",
    "    \n",
    "    results_df = pd.DataFrame.from_records(all_stats,  columns = \n",
    "    ['units_sold_1','revenue_1','profits_1', 'grmar_1',\n",
    "     'units_sold_2','revenue_2','profits_2', 'grmar_2',\n",
    "     'units_sold_3','revenue_3','profits_3', 'grmar_3',\n",
    "     'units_sold_4','revenue_4','profits_4', 'grmar_4',\n",
    "     'units_sold_5','revenue_5','profits_5', 'grmar_5',])\n",
    "        \n",
    "    final_stats.append([np.exp(P_1), np.exp(P_2), np.exp(P_3),\n",
    "                        np.exp(P_4), np.exp(P_5),\n",
    "                        results_df['units_sold_1'].mean(),\n",
    "                        results_df['units_sold_2'].mean(),\n",
    "                        results_df['units_sold_3'].mean(),\n",
    "                        results_df['units_sold_4'].mean(),\n",
    "                        results_df['units_sold_5'].mean(),\n",
    "                        results_df['grmar_1'].mean(),\n",
    "                        results_df['grmar_2'].mean(),\n",
    "                        results_df['grmar_3'].mean(),\n",
    "                        results_df['grmar_4'].mean(),\n",
    "                        results_df['grmar_5'].mean(),\n",
    "                        results_df['profits_1'].mean(),\n",
    "                        results_df['profits_2'].mean(),\n",
    "                        results_df['profits_3'].mean(),\n",
    "                        results_df['profits_4'].mean(),\n",
    "                        results_df['profits_5'].mean(),\n",
    "                        feat1,feat2,feat3,feat4,feat5,\n",
    "                        disp1,disp2,disp3,disp4,disp5])\n",
    "    \n",
    "final_stats_df = pd.DataFrame.from_records(final_stats, columns =\n",
    "                ['Price per Oz_1', 'Price per Oz_2',\n",
    "                 'Price per Oz_3', 'Price per Oz_4', 'Price per Oz_5',\n",
    "                 'Sales_1', 'Sales_2', 'Sales_3', 'Sales_4', 'Sales_5',\n",
    "                 'GrMar_1', 'GrMar_2', 'GrMar_3', 'GrMar_4', 'GrMar_5',\n",
    "                 'Profits_1', 'Profits_2', \n",
    "                 'Profits_3', 'Profits_4', 'Profits_5',\n",
    "                 'Feat_1', 'Feat_2', 'Feat_3', 'Feat_4', 'Feat_5',\n",
    "                 'Disp_1', 'Disp_2', 'Disp_3', 'Disp_4', 'Disp_5'])\n",
    "\n",
    "final_stats_df['Total Profits'] = final_stats_df['Profits_5']\\\n",
    "                                + final_stats_df['Profits_4']\\\n",
    "                                + final_stats_df['Profits_3']\\\n",
    "                                + final_stats_df['Profits_2']\\\n",
    "                                + final_stats_df['Profits_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "comprehensive-asian",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T02:39:44.847418Z",
     "start_time": "2021-03-31T02:39:44.828435Z"
    }
   },
   "outputs": [],
   "source": [
    "df_4_stats = final_stats_df \n",
    "df_4_stats.to_csv('df_4_stats.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entire-chancellor",
   "metadata": {},
   "source": [
    "### N 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "union-solution",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T02:39:44.852372Z",
     "start_time": "2021-03-31T02:39:44.849382Z"
    }
   },
   "outputs": [],
   "source": [
    "price_msettings_df = df_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "western-script",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T02:39:46.776492Z",
     "start_time": "2021-03-31T02:39:44.853371Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a8ad28775fd40178e7d7c6910e01c00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Monte Carlo Simulation\n",
    "\n",
    "# (Re-) Setting Seed, due to np limitations\n",
    "np.random.seed(42)\n",
    "\n",
    "# Number of simulations per combinations of prices across SKUs'\n",
    "number_sims = 100_000\n",
    "\n",
    "# Store results from each simulation here\n",
    "final_stats = []\n",
    "\n",
    "# Loop over price dataframe\n",
    "for i in tqdm(range(len(price_msettings_df))):\n",
    "    \n",
    "    # Extract price per SKU as log\n",
    "    P_1 = np.log(price_msettings_df.iloc[i, 0])\n",
    "    P_2 = np.log(price_msettings_df.iloc[i, 1])\n",
    "    P_3 = np.log(price_msettings_df.iloc[i, 2])\n",
    "    P_4 = np.log(price_msettings_df.iloc[i, 3])\n",
    "    P_5 = np.log(price_msettings_df.iloc[i, 4])\n",
    "    \n",
    "    # Extract marketing settings per SKU \n",
    "    disp1 = price_msettings_df.iloc[i, 5]\n",
    "    disp2 = price_msettings_df.iloc[i, 6]\n",
    "    disp3 = price_msettings_df.iloc[i, 7]\n",
    "    disp4 = price_msettings_df.iloc[i, 8]\n",
    "    disp5 = price_msettings_df.iloc[i, 9]\n",
    "    \n",
    "    feat1 = price_msettings_df.iloc[i, 10]\n",
    "    feat2 = price_msettings_df.iloc[i, 11]\n",
    "    feat3 = price_msettings_df.iloc[i, 12]\n",
    "    feat4 = price_msettings_df.iloc[i, 13]\n",
    "    feat5 = price_msettings_df.iloc[i, 14]\n",
    "    \n",
    "    # Placeholder\n",
    "    all_stats = []\n",
    "\n",
    "    # Begin Simulation Loop\n",
    "    for i in range(number_sims):\n",
    "        \n",
    "        ###########\n",
    "        #  SKU1   # \n",
    "        ###########\n",
    "        \n",
    "        # Sales\n",
    "        intercept_1 = np.random.normal(intercept_mu_1, intercept_sigma_1)\n",
    "        B1_1   = np.random.normal(B1_mu_P1_1, B1_sigma_P1_1)\n",
    "        B2_1   = np.random.normal(B2_mu_P3_1, B2_sigma_P3_1)\n",
    "        \n",
    "        sales_1 = np.exp(intercept_1 \\\n",
    "                + B1_1 * P_1 \\\n",
    "                + B2_1 * P_3 \\\n",
    "                + B3_mu_D1_1 * disp1 \\\n",
    "                + B4_mu_F1_1 * feat1)\n",
    "        \n",
    "        # Gross Margin\n",
    "        intercept_GR1 = np.random.normal(intercept_mu_GR1, intercept_sigma_GR1)\n",
    "        B1_GR1   = np.random.normal(B1_mu_GR1, B1_sigma_GR1)\n",
    "        \n",
    "        grmar_1 = intercept_GR1 + B1_GR1 * P_1\n",
    "        \n",
    "        # Profit\n",
    "        revenue_1 = sales_1 * oz_1 * np.exp(P_1)\n",
    "        profits_1 = revenue_1 * grmar_1\n",
    "        \n",
    "        \n",
    "        ###########\n",
    "        #  SKU2   # \n",
    "        ###########\n",
    "\n",
    "        # Sales\n",
    "        intercept_2 = np.random.normal(intercept_mu_2, intercept_sigma_2)\n",
    "        B1_2   = np.random.normal(B1_mu_P1_2, B1_sigma_P1_2)\n",
    "        B2_2   = np.random.normal(B2_mu_P2_2, B2_sigma_P2_2)   \n",
    "        \n",
    "        sales_2 = np.exp(intercept_2 \\\n",
    "                + B1_2 * P_1 \\\n",
    "                + B2_2 * P_2 \\\n",
    "                + B3_mu_D2_2 * disp2 \\\n",
    "                + B4_mu_F2_2 * feat2)\n",
    "        \n",
    "        # Gross Margin\n",
    "        intercept_GR2 = np.random.normal(intercept_mu_GR2, intercept_sigma_GR2)\n",
    "        B1_GR2   = np.random.normal(B1_mu_GR2, B1_sigma_GR2)\n",
    "        \n",
    "        grmar_2 = intercept_GR2 + B1_GR2 * P_2\n",
    "        \n",
    "        # Profit\n",
    "        revenue_2 = sales_2 * oz_2 * np.exp(P_2)\n",
    "        profits_2 = revenue_2 * grmar_2\n",
    "        \n",
    "                \n",
    "        ###########\n",
    "        #  SKU3   # \n",
    "        ###########\n",
    "        \n",
    "        # Sales\n",
    "        intercept_3 = np.random.normal(intercept_mu_3, intercept_sigma_3)\n",
    "        B1_3   = np.random.normal(B1_mu_P1_3, B1_sigma_P1_3)\n",
    "        B2_3   = np.random.normal(B2_mu_P3_3, B2_sigma_P3_3)   \n",
    "        B3_3   = np.random.normal(B3_mu_P4_3, B3_sigma_P4_3) \n",
    "\n",
    "        sales_3 = np.exp(intercept_3 \\\n",
    "                + B1_3 * P_1 \\\n",
    "                + B2_3 * P_3 \\\n",
    "                + B3_3 * P_4 \\\n",
    "                + B4_mu_D3_3 * disp3 \\\n",
    "                + B5_mu_F3_3 * feat3)\n",
    "        \n",
    "        # Gross Margin\n",
    "        intercept_GR3 = np.random.normal(intercept_mu_GR3, intercept_sigma_GR3)\n",
    "        B1_GR3   = np.random.normal(B1_mu_GR3, B1_sigma_GR3)\n",
    "        \n",
    "        grmar_3 = intercept_GR3 + B1_GR3 * P_3\n",
    "        \n",
    "        # Profit\n",
    "        revenue_3 = sales_3 * oz_3 * np.exp(P_3)\n",
    "        profits_3 = revenue_3 * grmar_3\n",
    "        \n",
    "        \n",
    "        ###########\n",
    "        #  SKU4   # \n",
    "        ###########\n",
    "        \n",
    "        # Sales\n",
    "        intercept_4 = np.random.normal(intercept_mu_4, intercept_sigma_4)\n",
    "        B1_4   = np.random.normal(B1_mu_P1_4, B1_sigma_P1_4)\n",
    "        B2_4   = np.random.normal(B2_mu_P3_4, B2_sigma_P3_4)   \n",
    "        B3_4   = np.random.normal(B3_mu_P4_4, B3_sigma_P4_4) \n",
    "        B4_4   = np.random.normal(B4_mu_P5_4, B4_sigma_P5_4)\n",
    "        \n",
    "        sales_4 = np.exp(intercept_4 \\\n",
    "                + B1_4 * P_1 \\\n",
    "                + B2_4 * P_3 \\\n",
    "                + B3_4 * P_4 \\\n",
    "                + B4_4 * P_5 \\\n",
    "                + B5_mu_D4_4 * disp4 \\\n",
    "                + B6_mu_F4_4 * feat4)\n",
    "        \n",
    "        # Gross Margin\n",
    "        intercept_GR4 = np.random.normal(intercept_mu_GR4, intercept_sigma_GR4)\n",
    "        B1_GR4   = np.random.normal(B1_mu_GR4, B1_sigma_GR4)\n",
    "        \n",
    "        grmar_4 = intercept_GR4 + B1_GR4 * P_4\n",
    "        \n",
    "        # Profit\n",
    "        revenue_4 = sales_4 * oz_4 * np.exp(P_4)\n",
    "        profits_4 = revenue_4 * grmar_4\n",
    "        \n",
    "        \n",
    "        ###########\n",
    "        #  SKU5   # \n",
    "        ###########\n",
    "        \n",
    "        # Sales\n",
    "        intercept_5 = np.random.normal(intercept_mu_5, intercept_sigma_5)\n",
    "        B1_5   = np.random.normal(B1_mu_P2_5, B1_sigma_P2_5)\n",
    "        B2_5   = np.random.normal(B2_mu_P3_5, B2_sigma_P3_5)   \n",
    "        B3_5   = np.random.normal(B3_mu_P4_5, B3_sigma_P4_5) \n",
    "        B4_5   = np.random.normal(B4_mu_P5_5, B4_sigma_P5_5) \n",
    "        \n",
    "        sales_5 = np.exp(intercept_5 \\\n",
    "                + B1_5 * P_2 \\\n",
    "                + B2_5 * P_3 \\\n",
    "                + B3_5 * P_4 \\\n",
    "                + B4_5 * P_5 \\\n",
    "                + B5_mu_D5_5 * disp5 \\\n",
    "                + B6_mu_F5_5 * feat5)\n",
    "        \n",
    "        # Gross Margin\n",
    "        intercept_GR5 = np.random.normal(intercept_mu_GR5, intercept_sigma_GR5)\n",
    "        B1_GR5   = np.random.normal(B1_mu_GR5, B1_sigma_GR5)\n",
    "        \n",
    "        grmar_5 = intercept_GR5 + B1_GR5 * P_5\n",
    "        \n",
    "        # Profit\n",
    "        revenue_5 = sales_5 * oz_5 * np.exp(P_5)\n",
    "        profits_5 = revenue_5 * grmar_5\n",
    "        \n",
    "        \n",
    "        ####################\n",
    "        #  Appending SKUs  # \n",
    "        ####################\n",
    "        \n",
    "        all_stats.append([sales_1, revenue_1, profits_1, grmar_1,\n",
    "                          sales_2, revenue_2, profits_2, grmar_2,\n",
    "                          sales_3, revenue_3, profits_3, grmar_3,\n",
    "                          sales_4, revenue_4, profits_4, grmar_4,\n",
    "                          sales_5, revenue_5, profits_5, grmar_5])\n",
    "    \n",
    "    results_df = pd.DataFrame.from_records(all_stats,  columns = \n",
    "    ['units_sold_1','revenue_1','profits_1', 'grmar_1',\n",
    "     'units_sold_2','revenue_2','profits_2', 'grmar_2',\n",
    "     'units_sold_3','revenue_3','profits_3', 'grmar_3',\n",
    "     'units_sold_4','revenue_4','profits_4', 'grmar_4',\n",
    "     'units_sold_5','revenue_5','profits_5', 'grmar_5',])\n",
    "        \n",
    "    final_stats.append([np.exp(P_1), np.exp(P_2), np.exp(P_3),\n",
    "                        np.exp(P_4), np.exp(P_5),\n",
    "                        results_df['units_sold_1'].mean(),\n",
    "                        results_df['units_sold_2'].mean(),\n",
    "                        results_df['units_sold_3'].mean(),\n",
    "                        results_df['units_sold_4'].mean(),\n",
    "                        results_df['units_sold_5'].mean(),\n",
    "                        results_df['grmar_1'].mean(),\n",
    "                        results_df['grmar_2'].mean(),\n",
    "                        results_df['grmar_3'].mean(),\n",
    "                        results_df['grmar_4'].mean(),\n",
    "                        results_df['grmar_5'].mean(),\n",
    "                        results_df['profits_1'].mean(),\n",
    "                        results_df['profits_2'].mean(),\n",
    "                        results_df['profits_3'].mean(),\n",
    "                        results_df['profits_4'].mean(),\n",
    "                        results_df['profits_5'].mean(),\n",
    "                        feat1,feat2,feat3,feat4,feat5,\n",
    "                        disp1,disp2,disp3,disp4,disp5])\n",
    "    \n",
    "final_stats_df = pd.DataFrame.from_records(final_stats, columns =\n",
    "                ['Price per Oz_1', 'Price per Oz_2',\n",
    "                 'Price per Oz_3', 'Price per Oz_4', 'Price per Oz_5',\n",
    "                 'Sales_1', 'Sales_2', 'Sales_3', 'Sales_4', 'Sales_5',\n",
    "                 'GrMar_1', 'GrMar_2', 'GrMar_3', 'GrMar_4', 'GrMar_5',\n",
    "                 'Profits_1', 'Profits_2', \n",
    "                 'Profits_3', 'Profits_4', 'Profits_5',\n",
    "                 'Feat_1', 'Feat_2', 'Feat_3', 'Feat_4', 'Feat_5',\n",
    "                 'Disp_1', 'Disp_2', 'Disp_3', 'Disp_4', 'Disp_5'])\n",
    "\n",
    "final_stats_df['Total Profits'] = final_stats_df['Profits_5']\\\n",
    "                                + final_stats_df['Profits_4']\\\n",
    "                                + final_stats_df['Profits_3']\\\n",
    "                                + final_stats_df['Profits_2']\\\n",
    "                                + final_stats_df['Profits_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "million-portfolio",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T02:39:46.797410Z",
     "start_time": "2021-03-31T02:39:46.777461Z"
    }
   },
   "outputs": [],
   "source": [
    "df_5_stats = final_stats_df \n",
    "df_5_stats.to_csv('df_5_stats.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sporting-evidence",
   "metadata": {},
   "source": [
    "# Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "potential-killer",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T02:41:35.227084Z",
     "start_time": "2021-03-31T02:41:35.118409Z"
    }
   },
   "outputs": [],
   "source": [
    "r1 = pd.read_csv('df_1_stats.csv')\n",
    "r2 = pd.read_csv('df_2_stats.csv')\n",
    "r3 = pd.read_csv('df_3_stats.csv')\n",
    "r4 = pd.read_csv('df_4_stats.csv')\n",
    "r5 = pd.read_csv('df_5_stats.csv')\n",
    "\n",
    "df_2500_top = pd.concat([r1,r2,r3,r4,r5])\n",
    "df_2500_top.to_csv('results_2500_top.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
